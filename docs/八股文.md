# 🔥八股文

# CPP基础

## 语言基础

### C和C++区别

C++是面向对象的语言，而C是面向过程的结构化编程语言；

C++具有重载、继承和多态三种特性；

C++相比C，增加了许多类型安全的功能，比如强制类型转换；

C++支持范式编程，比如模板类、函数模板等；

函数方面 C++ 中有重载和虚函数的概念，用以实现多态；

C++ 中增加了模板还重用代码，提供了更加强大的 STL 标准库。

### 内存模型

- **C/C++内存有哪几种类型？**

C++ 内存分区：**栈、堆、全局/静态存储区、常量存储区、代码区**。

**栈**：存放函数的局部变量、函数参数、返回地址等，由编译器自动分配和释放。

**堆**：动态申请的内存空间，就是由 malloc 分配的内存块，由程序员控制它的分配和释放，如果程序执行结束还没有释放，操作系统会自动回收。

**全局区/静态存储区（.bss 段和 .data 段）**：存放全局变量和静态变量，程序运行结束操作系统自动释放，在 C 语言中，未初始化的放在.bss 段中，初始化的放在 .data 段中，C++ 中不再区分了。

**常量存储区（.data 段**）：存放的是常量，不允许修改，程序运行结束自动释放。

**代码区（.text 段）**：存放代码，不允许修改，但可以执行。编译后的二进制文件存放在这里。

- **堆和栈的区别**

申请方式：栈是系统自动分配，堆是程序员主动申请。

存放的内容：栈中存放的是局部变量，函数的参数；堆中存放的内容由程序员控制；

空间大小不同：一般来讲在32位系统下，堆内存可以达到4G的空间，从这个角度来看堆内存几乎是没有什么限制的。但是对于栈来讲，一般都是有一定的空间大小的；

碎片问题不同：对于堆来讲，频繁的new/delete势必会造成内存空间的不连续，从而造成大量的碎片，使程序效率降低。对于栈来讲，则不会存在这个问题，因为栈是先进后出的，以至于永远都不可能有一个内存块从栈中间弹出，在他弹出之前，在他上面的后进的栈内容已经被弹出；

分配方式不同：堆都是动态分配的，没有静态分配的堆。栈有两种分配方式：静态分配和动态分配。静态分配是编译器完成的，比如局部变量的分配。动态分配由malloc函数进行分配，但是栈的动态分配和堆是不同的，他的动态分配是由编译器进行释放，无需我们手工实现；

分配效率不同：栈是机器系统提供的数据结构，计算机会在底层对栈提供支持：分配专门的奇存器存放栈的地址，压栈出栈都有专门的指令执行，这就决定了栈的效率比较高。堆则是C/C++函数库提供的，它的机制是很复杂的。

申请后系统响应：分配栈空间，如果剩余空间大于申请空间则分配成功，否则分配失败栈溢出；申请堆空间，堆在内存中呈现的方式类似于链表（记录空闲地址空间的链表），在链表上寻找第一个大于申请空间的节点分配给程序，将该节点从链表中删除，大多数系统中该块空间的首地址存放的是本次分配空间的大小，便于释放，将该块空间上的剩余空间再次连接在空闲链表上；

栈在内存中是连续的一块空间（向低地址扩展）最大容量是系统预定好的，堆在内存中的空间（向高地址扩展）是不连续的；

### 程序编译的过程

编译过程分为四个过程：**编译预处理，编译，汇编，链接**。

**编译预处理**：处理以 # 开头的指令；

**编译、优化**：将源码 .cpp 文件翻译成 .s 汇编代码；

**汇编**：将汇编代码 .s 翻译成机器指令 .o 文件；

**链接**：汇编程序生成的目标文件，即 .o 文件，并不会立即执行，因为可能会出现：.cpp 文件中的函数引用了另一个 .cpp文件中定义的符号或者调用了某个库文件中的函数。那链接的目的就是将这些文件对应的目标文件连接成一个整体，从而生成可执行的程序 .exe文件。

链接分为两种：

**静态链接**：代码从其所在的静态链接库中拷贝到最终的可执行程序中，在该程序被执行时，这些代码会被装入到该进程的虚拟地址空间中。

**动态链接**：代码被放到动态链接库或共享对象的某个目标文件中，链接程序只是在最终的可执行程序中记录了共享对象的名字等一些信息。在程序执行时，动态链接库的全部内容会被映射到运行时相应进行的虚拟地址的空间。

二者的优缺点：

**静态链接**：浪费空间，每个可执行程序都会有目标文件的一个副本，这样如果目标文件进行了更新操作，就需要重新进行编译链接生成可执行程序（更新困难）；优点就是执行的时候运行速度快，因为可执行程序具备了程序运行的所有内容。

**动态链接**：节省内存、更新方便，但是动态链接是在程序运行时，每次执行都需要链接，相比静态链接会有一定的性能损失。

### 内存泄漏

1. **什么是内存泄露**

内存泄漏：由于疏忽或错误导致的程序未能释放已经不再使用的内存。
进一步解释：

- 并非指内存从物理上消失，而是指程序在运行过程中，由于疏忽或错误而失去了对该内存的控制，从而造成了内存的浪费。
- 常指堆内存泄漏，因为堆是动态分配的，而且是用户来控制的，如果使用不当，会产生内存泄漏。
- 使用 malloc、calloc、realloc、new 等分配内存时，使用完后要调用相应的 free 或 delete释放内存，否则这块内存就会造成内存泄漏。
- 指针重新赋值

```php
char *p = (char *)malloc(10);
char *p1 = (char *)malloc(10);
p = np;
```

开始时，指针 p 和 p1 分别指向一块内存空间，但指针 p 被重新赋值，导致 p 初始时指向的那块内存空间无法找到，从而发生了内存泄漏。

2. **怎么防止内存泄漏？**

**防止内存泄漏的方法：**

- **内部封装**：将内存的分配和释放封装到类中，在构造的时候申请内存，析构的时候释放内存。（说明：但这样做并不是最佳的做法，在类的对象复制时，程序会出现同一块内存空间释放两次的情况）；

- **智能指针**：智能指针是 C++ 中已经对内存泄漏封装好了一个工具，可以直接拿来使用。

### 指针和引用的异同

指针和引用都是一种内存地址的概念，区别：指针是一个实体，引用只是一个别名。

在程序编译的时候，将指针和引用添加到符号表中。

指针指向一块内存，指针的内容是所指向的内存的地址，在编译的时候，则是将“指针变量名-指针变量的地址”添加到符号表中，所以说，指针包含的内容是可以改变的，允许拷贝和赋值，有 const 和非 const 区别，甚至可以为空，sizeof 指针得到的是指针类型的大小。

而对于引用来说，它只是一块内存的别名，在添加到符号表的时候，是将"引用变量名-引用对象的地址"添加到符号表中，符号表一经完成不能改变，所以引用必须而且只能在定义时被绑定到一块内存上，后续不能更改，也不能为空，也没有 const 和非 const 区别。

sizeof 引用得到代表对象的大小，而 sizeof 指针得到的是指针本身的大小。另外在参数传递中，指针需要被解引用后才可以对对象进行操作，而直接对引用进行的修改会直接作用到引用对象上。

作为参数时也不同，传指针的实质是传值，传递的值是指针的地址；传引用的实质是传地址，传递的是变量的地址。

### static、const、#define宏定义

- **static的用法**

static修饰**局部变量**：变量存放在静态数据区，其生命周期会一直延续到整个程序执行结束；

static修饰**全局变量**：会改变变量的作用域范围，变量只在本文件内部有效，对其他文件不可见；  

static修饰**函数**：会改变函数的作用域，函数只在本文件内部有效，对其他文件不可见；

static修饰**类**：如果对类中的某个函数用 static  修饰，则表示该函数属于一个类而不是属于此类的任何特定对象；如果对类中的某个变量进行 static 修饰，则表示该变量是类中所有对象所共有的，存储空间中只存在一个副本，可以通过类和对象去调用；

（类外定义和初始化，在类内仅是声明而已）

- **const的用法**

const修饰**常量**：定义时就初始化，以后不能更改；

const修饰**指针变量**和**引用变量**：如果 const 位于星号的左侧，则 const 就是用来修饰指针所指向的变量，即指针指向为常量；如果 const 位于星号的右侧，则 const 就是修饰指针本身，即指针本身是常量；

const修饰函数的**形参**：func(const int a)，该形参在函数里不能改变； 

const修饰**类成员变量**：const 成员变量，只在某个对象生命周期内是常量，而对于整个类而言是可以改变的。因为类可以创建多个对象，不同的对象其 const 数据成员值可以不同，所以不能在类的声明中初始化 const 成员变量，因为类的对象在没有创建时候，编译器不知道 const 成员变量的值是什么，const 成员变量的初始化只能在类的构造函数的初始化列表中进行。

const修饰**类成员函数**：防止成员函数修改对象的内容。要注意，const 关键字和 static 关键字对于成员函数来说是不能同时使用的，因为 static 关键字修饰静态成员函数不含有 this 指针，即不能实例化，const 成员函数又必须具体到某一个函数。

const 修饰**类对象**，定义常量对象：常量对象只能调用**常量函数**，不能调用非常量函数。而非常量对象可以调用类中的常量函数，也可以调用非常量函数。

**原因**：对象调用成员函数时，在形参列表的最前面加一个形参 this，但这是隐式的。this 指针是默认指向调用函数的当前对象的，所以，this 是一个常量指针，因为不可以修改 this 指针代表的地址。但当成员函数的参数列表（即小括号）后加了 const 关键字（void print() const;），此成员函数为**常量函数**，此时它的隐式this形参为 const test * const，即不可以通过 this 指针来改变指向对象的值。

- **const常量和#define宏定义的区别（编译阶段、安全性、内存占用等）**

对于 `define `来说， 宏定义实际上是在预编译阶段进行处理，没有类型，也就没有类型检查，仅仅做的是遇到宏定义进行字符替换，遇到多少次就字符替换，而且这个简单的字符替换过程中，很容易出现边界效应，达不到预期的效果。因为 define 宏定义仅仅是字符替换，因此运行时系统并不为宏定义分配内存，但是从汇编的角度来讲，define 以立即数的方式保留了多份数据的拷贝。

对于 `const `来说， const 是在编译期间进行处理的，const 有类型，也有类型检查，程序运行时系统会为 const 常量分配内存，而且从汇编的角度讲，const 常量在出现的地方保留的是真正数据的内存地址，只保留了一份数据的拷贝，省去了不必要的内存空间。而且，有时编译器不会为普通的 const 常量分配内存，而是直接将 const 常量添加到符号表中，省去了读取和写入内存的操作，效率更高。

### volatile 和 extern 关键字

**volatile 的作用**：当对象的值可能在程序的控制或检测之外被改变时，应该将该对象声明为 volatile，告知编译器不应对这样的对象进行优化。volatile不具有原子性。

**volatile 对编译器的影响**：使用该关键字后，编译器不会对相应的对象进行优化，即不会将变量从内存缓存到寄存器中，每次使用该变量必须从内存地址中读取，而不是保存在寄存器中的备份。防止多个线程有可能使用内存中的变量，有可能使用寄存器中的变量，从而导致程序错误。

用到volatile的几种情况：

- 并行设备的硬件寄存器（如状态寄存器）
- 中断服务子程序会访问到的非自动变量
- 多线程应用中被几个任务共享的变量

**volatile 三个特性**

易变性：在汇编层面反映出来，就是两条语句，下一条语句不会直接使用上一条语句对应的 volatile 变量的寄存器内容，而是重新从内存中读取。

不可优化性：volatile 告诉编译器，不要对我这个变量进行各种激进的优化，甚至将变量直接消除，保证程序员写在代码中的指令，一定会被执行。

顺序性：能够保证 volatile 变量之间的顺序性，编译器不会进行乱序优化。

**extern**

在 C 语言中，修饰符 extern 用在变量或者函数的声明前，用来说明 “此变量/函数是在别处定义的，要在此处引用”。

注意 extern 声明的位置对其作用域也有关系，如果是在 main 函数中进行声明的，则只能在 main 函数中调用，在其它函数中不能调用。其实要调用其它文件中的函数和变量，只需把该文件用 #include 包含进来即可，为啥要用 extern？因为用 extern 会加速程序的编译过程，这样能节省时间。

在 C++ 中 extern 还有另外一种作用，用于指示 C 或者 C＋＋函数的调用规范。比如在 C＋＋ 中调用 C 库函数，就需要在 C＋＋ 程序中用 extern “C” 声明要引用的函数。这是给链接器用的，告诉链接器在链接的时候用C 函数规范来链接。主要原因是 C＋＋ 和 C 程序编译完成后在目标代码中命名规则不同，用此来解决名字匹配的问题。

### #define和inline

- inline 函数工作原理

inline 内联函数不是在调用时发生控制转移关系，而是在编译阶段将函数体嵌入到每一个调用该函数的语句块中，编译器会将程序中出现内联函数的调用表达式用内联函数的函数体来替换。

普通函数是将程序执行转移到被调用函数所存放的内存地址，当函数执行完后，返回到执行此函数前的地方。转移操作需要保护现场，被调函数执行完后，再恢复现场，该过程需要较大的资源开销。

- 宏定义（define）和内联函数（inline）的区别

1. 内联函数是在编译时展开，而宏在编译预处理时展开；在编译的时候，内联函数直接被嵌入到目标代码中去，而宏只是一个简单的文本替换。

2. 内联函数是真正的函数，和普通函数调用的方法一样，在调用点处直接展开，避免了函数的参数压栈操作，减少了调用的开销。而宏定义编写较为复杂，常需要增加一些括号来避免歧义。

3. 宏定义只进行文本替换，不会对参数的类型、语句能否正常编译等进行检查。而内联函数是真正的函数，会对参数的类型、函数体内的语句编写是否正确等进行检查。

### new/delete, malloc/ free

- **malloc/free底层原理**

在标准C库中，提供了malloc/free函数分配释放内存，这两个函数底层是由brk、mmap、munmap这些系统调用实现的；

malloc是从堆里面申请内存，也就是说函数返回的指针是指向堆里面的一块内存。操作系统中有一个记录空闲内存地址的链表。当操作系统收到程序的申请时，就会遍历该链表，然后就寻找第一个空间大于所申请空间的堆结点，然后就将该结点从空闲结点链表中删除，并将该结点的空间分配给程序。


malloc的底层实现 ：

- 开辟空间小于128K时，通过**brk()函数**    
  - 将数据段.data的最高地址指针**_edata**向高地址移动，即**增加堆**的有效区域来申请内存空间
  - brk分配的内存需要等到高地址内存释放以后才能释放，这也是内存碎片产生的原因
- 开辟空间大于128K时，通过**mmap()函数**
  - 利用mmap系统调用，在堆和栈之间**文件映射区域**申请一块虚拟内存
  - 128K限制可由M_MMAP_THRESHOLD选项进行修改
  - mmap分配的内存可以单独释放
- 以上只涉及虚拟内存的分配，直到进程第一次访问其地址时，才会通过缺页中断机制分配到物理页中

- **new/delete底层原理**

`new` 和 `delete`是用户进行**动态内存申请和释放的操作符**，`operator new` 和`operator delete`是系统提供的全局函数，**new在底层调用operator new全局函数来申请空间**，**delete在底层通过operator delete全局函数来释放空间**

- 内置类型：
  如果申请的是内置类型的空间，new和malloc，delete和free基本类似。不同之处：new在申请空间失败时会抛异常，malloc在申请空间失败时会返回NULL。
- 自定义类型：
  - new的原理：
    1. 调用operator new函数申请空间；
    2. 在申请的空间上执行构造函数，完成对象的构造；
  - delete的原理：
    1. 在空间上执行析构函数，完成对象中资源的清理工作；
    2. 调用operator delete函数释放对象的空间；
  - new[N]的原理：
    1. 调用operator new[]函数，在operator new[]中实际调用operator new函数完成N个对象空间的申请；
    2. 在申请的空间上执行N次构造函数；
  - delete[N]的原理：
    1. 在释放的对象空间上执行N次析构函数，完成N个对象中资源的清理；
    2. 调用operator delete[]释放空间，实际在operator delete[]中调用operator delete来释放空间；

- **区别**

new、delete是C++中的操作符需要编译器支持，而malloc和free是标准库函数，需要加入头文件 stdlib.h。

malloc需要自行指定动态分配内存的大小，而new在指定指针类型之后可以自动分配内存，无需指定大小。

malloc返回的指针需要进行强制类型转换，而new操作符内存分配成功时，返回的是对象类型的指针，类型严格与对象匹配，无须进行类型转换；

new内存分配失败时，会抛出bad_alloc异常。malloc分配内存失败时返回NULL。

new会先调用operator new函数，申请足够的内存（通常底层使用malloc实现），然后调用类型的构造函数，初始化成员变量，最后返回自定义类型的指针。delete先调用析构函数，然后调用operator delete函数释放内存（通常底层使用free实现）。

malloc / free是库函数而不是运算符，只能动态的申请和释放内存，不在编译器控制范围之内，不能够自动调用构造函数和析构函数，无法强制要求其做自定义类型对象构造和析构工作（对于C++来说）。

### 智能指针

1. **智能指针的作用**

   智能指针的作用是**管理一个指针**，避免程序员申请的空间在函数结束时忘记释放，造成**内存泄漏**。使用智能指针可以很大程度上的避免这个问题，因为智能指针就是一个类，当超出了类的作用域时，类会自动调用析构函数，析构函数会自动释放资源。所以智能指针的作用原理就是在函数结束时自动释放内存空间，不需要手动释放内存空间。

   如果在程序中使用 new 从堆（自由存储区）分配内存，等到不再需要时，应使用 delete 将其释放，如果忘记释放，则会产生内存泄露。C++ 引入了智能指针 auto_ptr（C++98）， 以帮助自动完成这个过程。智能指针是行为类似于指针的类对象。

3. **有哪些智能指针**

   C++ 中有 4 种智能指针：auto_ptr、unique_ptr、shared_ptr、weak_ptr。其中 auto_ptr 在 C++11 中被弃用，weak_ptr 需要配合 shared_ptr 使用，并不能算是真正的智能指针。

3. **智能指针实现原理**

   智能指针解决问题的思想：将常规指针进行封装，当智能指针对象过期时，让它的析构函数对常规指针进行内存释放。

   - **auto_ptr**

   auto_ptr（C++98的方案，C++11已经废弃）：采用所有权模式，对于特定的对象，只能有一个智能指针可拥有它，这样只有拥有对象的智能指针的析构函数会删除该对象。然后，让赋值操作转让所有权。

   - **unique_ptr**

   unique_ptr（替代 auto_ptr）：也是采用所有权模式，实现独占式拥有或严格拥有概念，保证同一时间内只有一个智能指针可以指向该对象。

   - **shared_ptr**

   shared_ptr：采用引用计数实现共享式拥有概念。多个智能指针可以指向相同对象，该对象和其相关资源会在最后一个引用被销毁时候释放。它使用引用计数来表明资源被几个指针共享。例如，赋值时，计数将加 1，而指针过期时，计数将减 1。仅当最后一个指针过期时，才调用 delete。当两个对象相互使用一个shared_ptr成员变量指向对方，会造成循环引用，使引用计数失效，从而导致**内存泄漏**。shared_ptr内部的引用计数是线程安全的，但是对象的读取需要加锁。

   - **weak_ptr**

   weak_ptr：该类型指针通常不单独使用，只能和 shared_ptr 类型指针搭配使用。weak_ptr  类型指针并不会影响所指堆内存空间的引用计数，可以用来解**决循环引用问题**。

   为了**解决循环引用导致的内存泄漏**，引入了weak_ptr弱指针，weak_ptr的构造函数不会修改引用计数的值，从而不会对对象的内存进行管理，其类似一个普通指针，但不指向引用计数的共享内存，可以检测到所管理的对象是否已经被释放，从而避免非法访问。

   weak_ptr 是用来解决 shared_ptr 相互引用时的死锁问题，如果说两个 shared_ptr 相互引用，那么这两个指针的引用计数永远不可能下降为0，也就是资源永远不会释放。它是对对象的一种弱引用，不会增加对象的引用计数，和 shared_ptr 之间可以相互转化，shared_ptr 可以直接赋值给它，它可以通过调用 `lock `函数来获得shared_ptr。

   当两个智能指针都是 shared_ptr 类型的时候，析构时两个资源引用计数会减一，但是两者引用计数还是为 1，导致跳出函数时资源没有被释放（析构函数没有被调用），解决办法：把其中一个改为weak_ptr就可以。

5. **如何选择智能指针**

   如果程序要使用多个指向同一个对象的指针，应该选择 shared_ptr；

   如果程序不需要多个指向同一个对象的指针，则可以使用 unique_ptr;

   如果使用 new [] 分配内存，应该选择 unique_ptr;

   如果函数使用 new 分配内存，并返回指向该内存的指针，将其返回类型声明为 unique_ptr 是不错的选择。

5. **shared_ptr底层**

   shared_ptr的实现机制是在拷贝构造时使⽤同⼀份引⽤计数：

   （1）⼀个模板指针T* ptr，指向实际的对象；

   （2）⼀个引⽤次数，必须**new**出来的，不然会多个shared_ptr⾥⾯会有不同的引⽤次数⽽导致多次delete；

   （3）重载拷贝构造函数，使其引⽤次数加⼀；

   （4）重载析构函数，使引⽤次数减⼀并判断引⽤是否为零(是否调⽤delete)；

   （5）重载operator=（赋值运算符），如果原来的shared_ptr已经有对象，则让其引⽤次数减⼀并判断引⽤是否为零(是否调⽤delete)，然后将新的对象引⽤次数加⼀；

   （6）重载operator*（解引用运算符）和operator->（获取指针运算符），使得能像指针⼀样使⽤shared_ptr；

   代码实现：

```php
template<typename T>
class SharedPtr{
public:
    SharedPtr(T* ptr = NULL):_ptr(ptr), _pcount(new int(1)){}
    // 拷贝构造函数
    SharedPtr(const SharedPtr& s):_ptr(s._ptr), _pcount(s._pcount){
    	(*_pcount)++;
    }
    // 析构函数
    ~SharedPtr(){
        if (--(*(this->_pcount)) == 0){
            delete _ptr;
            delete _pcount;
            _ptr = NULL;
            _pcount = NULL;
        }
    }
    // 重载operator=（赋值运算符）
    SharedPtr<T>& operator=(const SharedPtr& s){
        if (this != &s){
            if (--(*(this->_pcount)) == 0){
                delete this->_ptr;
                delete this->_pcount;
            }
            _ptr = s._ptr;
            _pcount = s._pcount;
            *(_pcount)++;
        }
        return *this;
	}
    // 重载operator*
    T& operator*(){
        return *(this->_ptr);
    }
    // 重载operator->
    T* operator->(){
        return this->_ptr;
    }
private:
	T* _ptr;
	int* _pcount;	//指向引用计数的指针
};    
```

**线程安全问题**

[为什么多线程读写 shared_ptr 要加锁？ - 陈硕的Blog - C++博客 (cppblog.com)](http://www.cppblog.com/Solstice/archive/2013/01/28/197597.html)

shared_ptr的引用计数本身是线程安全（引用计数是原子操作）。
多个线程同时**读**同一个shared_ptr对象是线程安全的，如果是多个线程对同一个shared_ptr进行**读和写**，则需要加锁。
多线程读写shared_ptr所指向的同一个对象，不管是相同的shared_ptr对象，还是不同的，都需要加锁保护，因为shared_ptr有两个数据成员，读写操作不能原子化，使得多线程读写同一个shared_ptr对象需要加锁。

防止出现指针空悬。

6. **weak_ptr底层**

weak_ptr是为了配合shared_ptr⽽引⼊的⼀种智能指针，它的最⼤作⽤在于协助shared_ptr⼯作，像旁观者那样观测资源的使⽤情况，但weak_ptr没有共享资源，它的构造不会引起指针引⽤计数的增加。weak_ptr和shared_ptr指向相同内存，shared_ptr析构之后内存释放，在使⽤之前使⽤函数lock()检查weak_ptr是否为空指针。

shared_ptr和weak_ptr主要区别如下：

- shared_ptr对象能够初始化实际指向一个地址内容，而weak_ptr对象没办法直接初始化，需要用一个shared_ptr实例来初始化weak_ptr；

- weak_ptr不会影响shared_ptr的引用计数，因为它是一个弱引用，只是一个临时引用指向shared_ptr。即使用shared_ptr对象初始化weak_ptry也不会导致shared_ptr引用计数增加，依此特性可以解决shared_ptr的**循环引用**问题；

- weak_ptr没有解引用*和获取指针->运算符，它只能通过lock成员函数去获取对应的shared_ptr智能指针对象，从而获取对应的地址和内容。

7. **unique_ptr底层**

unique_ptr”唯⼀”拥有其所指对象，同⼀时刻只能有⼀个unique_ptr指向给定对象，离开作⽤域时，若其指向对象，则将其所指对象销毁（默认delete）。定义unique_ptr时需要将其绑定到⼀个new返回的指针上。

unique_ptr不⽀持普通的拷⻉和赋值，因为拥有指向的唯一对象，但是可以拷⻉和赋值⼀个将要被销毁的unique_ptr。可以通过release或者reset将指针所有权从⼀个（⾮const）unique_ptr 转移到另⼀个unique_ptr 。

一个unique_ptr怎么赋值给另一个unique_ptr对象？（std::move） 

借助 **std::move()** 可以实现将一个 unique_ptr 对象赋值给另一个 unique_ptr 对象，其目的是实现所有权的转移。

```cpp
// A 作为一个类 
std::unique_ptr<A> ptr1(new A());
std::unique_ptr<A> ptr2 = std::move(ptr1);
```

###  C++11的新特性

nullptr替代 NULL；引入了 auto 和 decltype 这两个关键字实现了类型推导；基于范围的 for 循环for(auto& i : res){}；类和结构体的中初始化列表；Lambda 表达式（匿名函数）；std::forward_list（单向链表）；右值引用和move语义。

**1. auto 类型推导**
auto 关键字：自动类型推导，编译器会在 **编译期间** 通过初始值推导出变量的类型，通过 auto 定义的变量必须有初始值。

**2. decltype 类型推导**
decltype 是“declare type”的缩写，译为“声明类型”。和 auto 的功能一样，都用来在**编译时期**进行自动类型推导。如果希望从表达式中推断出要定义的变量的类型，但是不想用该表达式的值初始化变量，这时就不能再用 auto。decltype 作用是选择并返回操作数的数据类型。

auto和decltype的区别：

```php
auto var = val1 + val2; 
decltype(val1 + val2) var1 = 0; 
```

- auto 根据 **=** 右边的初始值 val1 + val2 推导出变量的类型，并将该初始值赋值给变量 var；decltype 根据 val1 + val2 表达式推导出变量的类型，变量的初始值和与表达式的值无关。
- auto 要求变量必须初始化，因为它是根据初始化的值推导出变量的类型，而 decltype 不要求，定义变量的时候可初始化也可以不初始化。

**3. lambda 表达式**
lambda 表达式，又被称为 lambda 函数或者 lambda 匿名函数。

lambda匿名函数的定义:

```php
[capture list] (parameter list) -> return type
{
   function body;
};
```

其中：

- capture list：捕获列表，指 lambda 所在函数中定义的局部变量的列表，通常为空。
- return type、parameter list、function body：分别表示返回值类型、参数列表、函数体，和普通函数一样。

```php
#include <iostream>
#include <algorithm>
using namespace std;

int main()
{
    int arr[4] = {4, 2, 3, 1};
    //对 a 数组中的元素进行升序排序
    sort(arr, arr+4, [=](int x, int y) -> bool{ return x < y; } );
    for(int n : arr){
        cout << n << " ";
    }
    return 0;
}
```

**4. 范围 for 语句**

```php
for (declaration : expression){
    statement
}
```

参数的含义：

- expression：必须是一个序列，例如用花括号括起来的初始值列表、数组、vector ，string等，这些类型的共同特点是拥有能返回迭代器的 beign、end 成员。
- declaration：此处定义一个变量，序列中的每一个元素都能转化成该变量的类型，常用 auto 类型说明符。

**5. 右值引用**
右值引用：绑定到右值的引用，用 **&&** 来获得右值引用，右值引用只能绑定到要销毁的对象。为了和右值引用区分开，常规的引用称为左值引用。

```php
#include <iostream>
#include <vector>
using namespace std;
int main()
{
    int var = 42;
    int &l_var = var;
    int &&r_var = var; // 错误：不能将右值引用绑定到左值上

    int &&r_var2 = var + 40; // 正确：将 r_var2 绑定到求和结果上
    return 0;
}
```

左值：指表达式结束后依然存在的持久对象，右值：表达式结束就不再存在的临时对象，左值和右值的区别：左值持久，右值短暂。

右值引用和左值引用的区别：

- 左值引用不能绑定到要转换的表达式、字面常量或返回右值的表达式。右值引用恰好相反，可以绑定到这类表达式，但不能绑定到一个左值上。
- 右值引用必须绑定到右值的引用，通过 **&&** 获得。右值引用只能绑定到一个将要销毁的对象上，因此可以自由地移动其资源。

**std::move** 可以将一个左值强制转化为右值，继而可以通过右值引用使用该值，以用于移动语义。

```php
#include <iostream>
using namespace std;

void fun1(int& tmp) { 
  cout << "fun1(int& tmp):" << tmp << endl; 
} 

void fun2(int&& tmp) { 
  cout << "fun2(int&& tmp)" << tmp << endl; 
} 

int main() { 
  int var = 11; 
  fun1(12); // 错误：不能将左值引用绑定到右值上
  fun1(var);// 正确
  fun2(1); 	// 正确
}
```

**6. 标准库 move() 函数**
move() 函数：通过该函数可获得绑定到左值上的右值引用，该函数包括在 utility 头文件中。

**std::move()** 函数原型：

```cpp
template <typename T>
typename remove_reference<T>::type&& move(T&& t)
{
	return static_cast<typename remove_reference<T>::type &&>(t);
}
```

说明：引用折叠原理

- 右值传递给上述函数的形参 T&& 依然是右值，即 T&& && 相当于 T&&。
- 左值传递给上述函数的形参 T&& 依然是左值，即 T&& & 相当于 T&。

小结：通过引用折叠原理可以知道，move() 函数的形参既可以是左值也可以是右值。

**remove_reference** 具体实现：

```php
//原始的，最通用的版本
template <typename T> struct remove_reference{
    typedef T type;  //定义 T 的类型别名为 type
};
 
//部分版本特例化，将用于左值引用和右值引用
template <class T> struct remove_reference<T&> //左值引用
{ typedef T type; }
 
template <class T> struct remove_reference<T&&> //右值引用
{ typedef T type; }   
  
//举例如下,下列定义的a、b、c三个变量都是int类型
int i;
remove_refrence<decltype(42)>::type a;             //使用原版本，
remove_refrence<decltype(i)>::type  b;             //左值引用特例版本
remove_refrence<decltype(std::move(i))>::type  b;  //右值引用特例版本 
```

举例：

```php
int var = 10; 

转化过程：
1. std::move(var) => std::move(int&& &) => 折叠后 std::move(int&)
2. 此时：T 的类型为 int&，typename remove_reference<T>::type 为 int，这里使用 remove_reference 的左值引用的特例化版本
3. 通过 static_cast 将 int& 强制转换为 int&&

整个std::move被实例化如下
string&& move(int& t) 
{
    return static_cast<int&&>(t); 
}
```

总结std::move() 实现原理：

- 利用引用折叠原理将右值经过 T&& 传递类型保持不变还是右值，而左值经过 T&&变为普通的左值引用，以保证模板可以传递任意实参，且保持类型不变；
- 然后通过 remove_refrence 移除引用，得到具体的类型 T；
- 最后通过 static_cast<> 进行强制类型转换，返回 T&& 右值引用。

**7. 智能指针**
相关知识已在前面中进行了详细的说明，这里不再重复。

**8. delete 函数和 default 函数**

- delete 函数：`= delete` 表示该函数不能被调用。
- default 函数：`= default` 表示编译器生成默认的函数，例如：生成默认的构造函数。

```cpp
#include <iostream>
using namespace std;

class A
{
public:
	A() = default; // 表示使用默认的构造函数
	~A() = default;	// 表示使用默认的析构函数
	A(const A &) = delete; // 表示类的对象禁止拷贝构造
	A &operator=(const A &) = delete; // 表示类的对象禁止拷贝赋值
};
int main()
{
	A ex1;
	A ex2 = ex1; // error: use of deleted function 'A::A(const A&)'
	A ex3;
	ex3 = ex1; // error: use of deleted function 'A& A::operator=(const A&)'
	return 0;
}
```

### 四种强制转换

C++ 的四种强制转换包括：**static_cast, dynamic_cast, const_cast, reinterpret_cast**

基本用法：`static_cast<type-id> expression`，其他类似`xxx_cast<newType>(data)`。

**static_cast**

- 使用场景：

a、用于类层次结构中基类和派生类之间指针或引用的转换

上行转换（派生类---->基类）是安全的；

下行转换（基类---->派生类）由于没有动态类型检查，所以是不安全的。

b、用于基本数据类型之间的转换，如把int转换为char，这种带来安全性问题由程序员来保证

c、把空指针转换成目标类型的空指针

d、把任何类型的表达式转为void类型

- 使用特点

a、主要执行非多态的转换操作，用于代替C中通常的转换操作；

b、隐式转换都建议使用static_cast进行标明和替换。

**dynamic_cast**

专门用于派生类之间的转换，type-id 必须是类指针，类引用或 void*，对于下行转换是安全的，当类型不一致时，转换过来的是空指针，而static_cast，当类型不一致时，转换过来的事错误意义的指针，可能造成非法访问等问题。

- 使用场景：只有在派生类之间转换时才使用dynamic_cast，type-id必须是类指针，类引用或者void*。

- 使用特点：

a、基类必须要有虚函数，因为dynamic_cast是运行时类型检查，需要运行时类型信息，而这个信息是存储在类的虚函数表中，只有一个类定义了虚函数，才会有虚函数表（如果一个类没有虚函数，那么一般意义上，这个类的设计者也不想它成为一个基类）。

b、对于下行转换，dynamic_cast是安全的（当类型不一致时，转换过来的是空指针），而static_cast是不安全的（当类型不一致时，转换过来的是错误意义的指针，可能造成踩内存，非法访问等各种问题）

c、dynamic_cast还可以进行交叉转换

**const_cast**

专门用于 const 属性的转换，去除 const 性质，或增加 const 性质， 是四个转换符中唯一一个可以操作常量的转换符。

- 使用场景：

a、常量指针转换为非常量指针，并且仍然指向原来的对象

b、常量引用被转换为非常量引用，并且仍然指向原来的对象

- 使用特点：

a、cosnt_cast是四种类型转换符中唯一可以对常量进行操作的转换符

b、去除常量性是一个危险的动作，尽量避免使用。一个特定的场景是：类通过const提供重载时，一般都是非常量函数调用`const_cast<const T>`将参数转换为常量，然后调用常量函数，然后得到结果再调用`const_cast <T>`去除常量性。

**reinterpret_cast**

不到万不得已，不要使用这个转换符，高危操作。使用特点：从底层对数据进行重新解释，依赖具体的平台，可移植性差；可以将整形转 换为指针，也可以把指针转换为数组；可以在指针和引用之间进行肆无忌惮的转换。

- 使用场景：不到万不得已，不用使用这个转换符，高危操作

- 使用特点：　　

a、reinterpret_cast是从底层对数据进行重新解释，依赖具体的平台，可移植性差

b、reinterpret_cast可以将整型转换为指针，也可以把指针转换为数组

c、reinterpret_cast可以在指针和引用里进行肆无忌惮的转换

> 自动类型转换（隐式）：利用编译器内置的转换规则，或者用户自定义的转换构造函数以及类型转换函数（这些都可以认为是已知的转换规则）。例如从 int 到 double、从派生类到基类、从type *到void *、从 double 到 Complex 等。type *是一个具体类型的指针，例如int *、double *、Student *等，它们都可以直接赋值给void *指针。例如，malloc() 分配内存后返回的就是一个void *指针，我们必须进行强制类型转换后才能赋值给指针变量。
>
> 强制类型转换（显式）：隐式不能完成的类型转换工作，就必须使用强制类型转换：(new_type) expression。
>
> 数据类型转换的本质：对数据所占用的二进制位做出重新解释。
>
> 隐式类型转换：编译器可以根据已知的转换规则来决定是否需要**修改**数据的二进制位。
>
> 强制类型转换：由于没有对应的转换规则，所以能做的事情仅仅是**重新解释**数据的二进制位，但无法对数据的二进制位做出修正。

### class 和 struct 的异同

struct 和 class 都可以自定义数据类型，也支持继承操作。

struct 中默认的访问级别是 public，默认的继承级别也是 public；class 中默认的访问级别是 private，默认的继承级别也是 private。

当 class 继承 struct 或者 struct 继承 class 时，默认的继承级别取决于 class 或 struct 本身，class（private 继承），struct（public 继承），即取决于派生类的默认继承级别。

class 可以用于定义模板参数，struct 不能用于定义模板参数。

### memset, memcpy, strcpy函数

strcpy函数的原型：`char* strcpy(char* dest, const char* src)`， strcpy的作用是拷贝字符串，当它遇到'`\0`'时结束拷贝。

memcpy函数的原型：`void *memcpy( void *dest, const void *src, size_t count )`，memcpy用来做内存拷贝，可以拿它拷贝任何数据类型的对象，可以指定拷贝的数据长度。

memset函数的原型：`memset(void *s, int ch,size_t n)`，memset的作用是对一段内存空间全部设置为某个字符，常用在内存空间的初始化。

strcpy，memcpy和memset主要有以下三点区别：

1. 复制内容不同，strcpy只能复制字符串，而memcpy可以复制任一内容，比如整形、结构体等。所以在复制字符串时会用strcpy(因为效率原因)，而复制其他类型数据一般会用memcpy。

2. 从参数可以看出复制方法也不尽相同。strcpy不需要指定特定长度，遇到“\0”才会结束，所以使用不当容易造成溢出。memcpy则是根据第三个参数决定复制长度。

3. 将s中当前位置后面的n个字节用 ch 替换并返回 s，作用是在一段内存块中填充某个给定的值，它是对较大的结构体或数组进行清零的一种快速操作。

## 面向对象

### 三大特性

C++ 面向对象的三大特征是：封装、继承、多态。

**封装**

就是把客观事物封装成抽象的类，并且类可以把自己的数据和方法只让信任的类或者对象操作，对不可信的进行信息隐藏。一个类就是一个封装了数据以及操作这些数据的代码的逻辑实体。

在一个对象内部，某些代码或某些数据可以是私有的，不能被外界访问。通过这种方式，对象对内部数据提供了不同级别的保护，以防止程序中无关的部分意外的改变或错误的使用了对象的私有部分。

**继承**

是指可以让某个类型的对象获得另一个类型的对象的属性的方法。它支持按级分类的概念。继承是指这样一种能力：它可以使用现有类的所有功能，并在无需重新编写原来的类的情况下对这些功能进行扩展。

通过继承创建的新类称为“子类”或者“**派生类**”，被继承的类称为“**基类**”、“父类”或“超类”。继承的过程，就是从一般到特殊的过程。要实现继承，可以通过“继承”和“组合”来实现。

继承概念的实现方式有两类：

**实现继承**：实现继承是指直接使用基类的属性和方法而无需额外编码的能力。

**接口继承**：接口继承是指仅使用属性和方法的名称、但是子类必需提供实现的能力。

**多态**

就是向不同的对象发送同一个消息，不同对象在接收时会产生不同的行为（即方法）。即一个接口，可以实现多种方法。（重载实现编译时多态，虚函数实现运行时多态）

多态分为两类：

- **静态多态**：函数重载和运算符重载属于静态多态，复用函数名；
- **动态多态**：派生类和虚函数实现运行时多态。

**静态多态**和**动态多态**区别：

- 静态多态的函数地址早绑定 - 编译阶段确定函数地址
- 动态多态的函数地址晚绑定 - 运行阶段确定函数地址

**多态满足条件**：有继承关系；子类重写父类中的虚函数；

**多态使用条件**：父类指针或引用指向子类对象；

**多态的优点**：代码组织结构清晰；可读性强；利于前期和后期的扩展以及维护

### 继承

[C++之继承_浮沉一只白的博客-CSDN博客_c++ 继承](https://blog.csdn.net/m0_57234892/article/details/123892631)

- 三种继承方式

**private, public, protected的访问范围：**

private: 只能由该类中的函数、其友元函数访问，不能被任何其他访问，该类的对象也不能访问；

protected: 可以被该类中的函数、子类的函数、以及其友元函数访问，但不能被该类的对象访问；

public: 可以被该类中的函数、子类的函数、其友元函数访问，也可以由该类的对象访问；

**类继承后方法属性变化:**

使用private继承，父类的所有方法在子类中变为private；

使用protected继承，父类的protected和public方法在子类中变为protected，而private方法不变；

使用public继承，父类中的方法属性不发生改变；

派生类的访问方式会变为基类的访问方式和继承方式取权限最小的那个。

**总结：**

基类`private`成员在派生类中无论以什么方式继承都是不可见的。这里的不可见是指基类的私有成员还是被继承到了派生类对象中，但是语法上限制派生类对象不管在类里面还是类外面都不能去访问它。

如果基类成员不想在类外直接被访问，但需要在派生类中能访问，就定义为`protected`。可以看出保护成员限定符是因继承才出现的。

class的默认继承方式为private，而struct的默认继承方式为public。

实际应用多为public继承。

- 菱形继承

单继承：一个子类只有一个直接父类时称这个继承关系为单继承。

多继承：一个子类有两个或两个以上直接父类时称这个继承关系称为多继承。

两个派生类继承同一个基类，又有某个类同时继承者两个派生类，这种继承被称为**菱形继承**。

菱形继承带来的主要问题是子类继承两份相同的数据，导致数据的冗余性和二义性，可以用**虚继承**来解决。

可以通过指定访问哪个父类来解决二义性：

```php
class Person{
public:
	string _name; // 姓名
};

class Student : public Person{
protected:
	int _num; //学号
};

class Teacher : public Person{
protected:
	int _id; // 职工编号
};

class Assistant : public Student, public Teacher{
protected:
	string _Course; // 课程
};

void Test(){
	Assistant a;
	a._name = "peter";	// 这样会出现二义性无法明确知道访问的是哪一个
	a.Student::_name = "Tom"; // 正确
	a.Teacher::_name = "Jack"; // 正确
}
```

而为了解决冗余性，则出现了**菱形虚继承**。

在继承方式前面加上 `virtual `关键字就是虚继承，

```php
class Person{
public:
	string _name; // 姓名
};

class Student : virtual public Person{
protected:
	int _num; //学号
};

class Teacher : virtual public Person{
protected:
	int _id; // 职工编号
};

class Assistant : public Student, public Teacher{
protected:
	string _Course; // 课程
};

int main(){
	Assistant a;
	a.Student::_name = "Tom";
	a.Teacher::_name = "Jack";
	a._name = "peter"; // 正确
	return 0;
}
```

这段代码使用虚继承重新实现了菱形继承，这样在派生类 Assistant 中就只保留了一份成员变量 _name，直接访问就不会再有歧义了。

虚继承的目的是让某个类做出声明，承诺愿意共享它的基类。其中，这个被共享的基类就称为**虚基类**，本例中的 Person 就是一个虚基类。在这种机制下，不论虚基类在继承体系中出现了多少次，在派生类中都只包含一份虚基类的成员。

- 继承和组合之间的区别与联系

⼀个类⾥⾯的数据成员是另⼀个类的对象，即内嵌其他类的对象作为⾃⼰的成员；创建组合类的对象：⾸先创建各个内嵌对象，难点在于构造函数的设计。创建对象时既要对基本类型的成员进⾏初始化，⼜要对内嵌对象进⾏初始化。

创建组合类对象，构造函数的执⾏顺序：先调⽤内嵌对象的构造函数，然后按照内嵌对象成员在组合类中的定义顺序，与组合类构造函数的初始化列表顺序⽆关。然后执⾏组合类构造函数的函数体，析构函数调⽤顺序相反。

- 友元

在程序里有些私有属性也想让类外特殊的一些函数或者类进行访问，就需要用到**友元**。友元的**目的**就是让一个函数或者类访问另一个类中私有成员。友元的关键字为 **friend**，友元的三种实现：全局函数做友元、类做友元、成员函数做友元。

[论C++的自我修养（4）友元_海岸星的清风的博客-CSDN博客](https://blog.csdn.net/weixin_42461320/article/details/122900371)

### 重载、重写和隐藏

**隐藏**：是指派生类的函数屏蔽了与其同名的基类函数，主要只要同名函数，不管参数列表是否相同，基类函数都会被隐藏。

```php
#include <iostream>
using namespace std;

class Base{
public:
    void fun(int tmp, float tmp1) { cout << "Base::fun(int tmp, float tmp1)" << endl; }
};

class Derive : public Base{
public:
    void fun(int tmp) { cout << "Derive::fun(int tmp)" << endl; } // 隐藏基类中的同名函数
};

int main(){
    Derive ex;
    ex.fun(1);       // Derive::fun(int tmp)
    ex.fun(1, 0.01); // error: candidate expects 1 argument, 2 provided
    return 0;
}
```

**说明**：上述代码中 ex.fun(1, 0.01); 出现错误，说明派生类中将基类的同名函数隐藏了。若是想调用基类中的同名函数，可以加上类型名指明 ex.Base::fun(1, 0.01);，这样就可以调用基类中的同名函数。

问题：继承中同名的静态成员在子类对象上如何进行访问？

静态成员和非静态成员出现同名，处理方式一致

- 访问子类同名成员 直接访问即可
- 访问父类同名成员 需要加作用域

**重载**：是指同一可访问区内被声明几个具有不同参数列（参数的类型、个数、顺序）的同名函数，根据参数列表确定调用哪个函数，重载不关心函数返回类型。

```php
class A{
public:
    void fun(int tmp);
    void fun(float tmp);        // 重载 参数类型不同（相对于上一个函数）
    void fun(int tmp, float tmp1); // 重载 参数个数不同（相对于上一个函数）
    void fun(float tmp, int tmp1); // 重载 参数顺序不同（相对于上一个函数）
    int fun(int tmp);            //错误：注意重载不关心函数返回类型
};
```

**重写(覆盖)**：是指派生类中存在重新定义的函数。函数名、参数列表、返回值类型都必须同基类中被重写的函数一致，只有函数体不同。派生类调用时会调用派生类的重写函数，不会调用被重写函数。重写的基类中被重写的函数必须有 virtual 修饰。

```php
#include <iostream>
using namespace std;

class Base{
public:
    virtual void fun(int tmp) { cout << "Base::fun(int tmp) : " << tmp << endl; }
};

class Derived : public Base{
public:
    virtual void fun(int tmp) { cout << "Derived::fun(int tmp) : " << tmp << endl; } // 重写基类中的 fun 函数
};

int main(){
    Base *p = new Derived();
    p->fun(3); // Derived::fun(int) : 3
    return 0;
}
```

**重写和重载的区别：**

- **范围区别**：对于类中函数的重载或者重写而言，重载发生在同一个类的内部，重写发生在不同的类之间（子类和父类之间）。
- **参数区别**：重载的函数需要与原函数有相同的函数名、不同的参数列表，不关注函数的返回值类型；重写的函数的函数名、参数列表和返回值类型都需要和原函数相同，父类中被重写的函数需要有 virtual 修饰。
- **virtual 关键字**：重写的函数基类中必须有 virtual关键字的修饰，重载的函数可以有 virtual 关键字的修饰也可以没有。

**隐藏和重写，重载的区别：**

- **范围区别**：隐藏与重载范围不同，隐藏发生在不同类中。
- **参数区别**：隐藏函数和被隐藏函数参数列表可以相同，也可以不同，但函数名一定相同；当参数不同时，无论基类中的函数是否被 virtual修饰，基类函数都是被隐藏，而不是重写。

### 构造函数和析构函数

- **构造函数**：主要作用在于创建对象时，为对象的成员属性赋值。构造函数由编译器自动调用，无须手动调用。

**构造函数语法：**`类名(){}`

1. 构造函数，没有返回值也不写void
2. 函数名称与类名相同
3. 构造函数可以有参数，因此可以发生重载
4. 程序在调用对象时候会自动调用构造函数，无须手动调用，而且只会调用一次

- **析构函数**：主要作用在于对象**销毁前**系统自动调用，执行一些清理工作。

**析构函数语法：** `~类名(){}`

1. 析构函数，没有返回值也不写void
2. 函数名称与类名相同，在名称前加上符号 ~
3. 析构函数不可以有参数，因此不可以发生重载
4. 程序在对象销毁前会自动调用析构，无须手动调用，而且只会调用一次

- 构造函数的两种分类方式：

1. 按参数分为： 有参构造和无参构造

2. 按类型分为： 普通构造和拷贝构造

此外，C++还提供了**初始化列表**语法，用来初始化属性。**语法：**`构造函数()：属性1(值1),属性2（值2）... {}`。

所以**类成员初始化方式**有两种：1. 赋值初始化，通过在函数体内进行赋值初始化；2. 列表初始化，在冒号后使用初始化列表进行初始化。

这两种方式的主要**区别**在于：

对于在函数体中初始化，是在所有的数据成员被分配内存空间后才进行的。而列表初始化是给数据成员分配内存空间时就进行初始化，也就是说分配一个数据成员只要冒号后有此数据成员的赋值表达式(此表达式必须是括号赋值表达式)，那么分配了内存空间后在进入函数体之前给数据成员赋值，初始化这个数据成员，此时函数体还未执行。

那为什么用成员初始化列表会快一些呢？

因为方法一（赋值初始化）是在构造函数当中做赋值的操作，而方法二（列表初始化）是做纯粹的初始化操作。C++的赋值操作是会产生临时对象的，临时对象的出现会降低程序的效率。

- **执行顺序**

**构造函数顺序**

1. 基类构造函数。如果有多个基类，则构造函数的调用顺序是某类在类派生表中出现的顺序，而不是它们在成员初始化表中的顺序。

2. 成员类对象构造函数。如果有多个成员类对象则构造函数的调用顺序是对象在类中被声明的顺序，而不是它们出现在成员初始化表中的顺序。

3. 派生类构造函数。

**析构函数顺序**

1. 调用派生类的析构函数；

2. 调用成员类对象的析构函数；

3. 调用基类的析构函数。

- **构造函数、析构函数可否抛出异常**

析构函数：

如果析构函数抛出异常，则异常点之后的程序不会执行，如果析构函数在异常点之后执行了某些必要的动作比如释放某些资源，则这些动作不会执行，会造成诸如资源泄漏的问题。通常异常发生时，C++机制会调用已经构造对象的析构函数来释放资源，此时如析构函数本身也抛出异常，则前一个异常尚未处理，又有新的异常，会造成程序崩溃的问题。

那么如果无法保证在析构函数中不发生异常该怎么办？那就是把异常完全封装在析构函数内部，决不让异常抛出析构函数之外。这是一种非常简单，也非常有效的方法。

构造函数：

构造函数中抛出异常，会导致析构函数不能被调用，但对象本身已申请到的内存资源会被系统释放（已申请到资源的内部成员变量会被系统依次逆序调用其析构函数）。在构造函数中抛出异常，在概念上将被视为该对象没有被成功构造，因此当前对象的析构函数就不会被调用。因为析构函数不能被调用，所以可能会造成内存泄露或系统资源未被释放。

构造函数中可以抛出异常，但必须保证在构造函数抛出异常之前把系统资源释放掉，防止内存泄露。构造函数中尽量不要抛出异常，能避免的就避免，如果必须，要考虑不要内存泄露。

解决办法：在Catch 块里面释放已经申请的资源 或者 用智能指针把资源当做对象处理。

### 深拷贝和浅拷贝

如果一个类拥有资源，该类的对象进行复制时，**如果资源重新分配，就是深拷贝，否则就是浅拷贝。**

- **深拷贝**：该对象和原对象占用不同的内存空间，既拷贝存储在栈空间中的内容，又拷贝存储在堆空间中的内容。
- **浅拷贝**：该对象和原对象占用同一块内存空间，仅拷贝类中位于栈空间中的内容。

当类的成员变量中有指针变量时，最好使用深拷贝。因为当两个对象指向同一块内存空间，如果使用浅拷贝，当其中一个对象的删除后，该块内存空间就会被释放，另外一个对象指向的就是垃圾内存。

当出现类的等号赋值时，会调用拷贝函数，在未定义显示拷贝构造函数的情况下， 系统会调用默认的拷贝函数－即浅拷贝，它能够完成成员的一一复制。当数据成员中没有指针时，浅拷贝是可行的。

但当数据成员中有指针时，如果采用简单的浅拷贝，则两类中的两个指针指向同一个地址，当对象快要结束时，会调用两次析构函数，而导致指野指针的问题。

所以，这时必需采用深拷贝。深拷贝与浅拷贝之间的区别就在于**深拷贝会在堆内存中另外申请空间来存储数据，从而也就解决来野指针的问题**。简而言之，当数据成员中有指针时，必需要用深拷贝更加安全。

```php
class Person {
public:
	//无参（默认）构造函数
	Person() {
		cout << "无参构造函数!" << endl;
	}
	//有参构造函数
	Person(int age ,int height) {
		cout << "有参构造函数!" << endl;
		m_age = age;
		m_height = new int(height);
	}
	//拷贝构造函数  
	Person(const Person& p) {
		cout << "拷贝构造函数!" << endl;
		//如果不利用深拷贝在堆区创建新内存，会导致浅拷贝带来的重复释放堆区问题
		m_age = p.m_age;
		m_height = new int(*p.m_height);
	}
	//析构函数
	~Person() {
		cout << "析构函数!" << endl;
		if (m_height != NULL){
			delete m_height;
		}
	}
public:
	int m_age;
	int* m_height;
};

```

### 虚函数

- **虚函数的实现原理**

首先C++中多态的实现是在基类的函数前加上 `virtual`关键字，在派生类中重写该函数，运行时将会根据对象的实际类型来调用相应的函数。如果对象类型是派生类，就调用派生类的函数，如果是基类，就调用基类的函数。

实际上，当一个类中包含虚函数时，编译器会为该类生成一个**虚函数表**，保存该类中虚函数的地址。同样，派生类继承基类，派生类中自然一定有虚函数，所以编译器也会为派生类生成自己的虚函数表。当我们定义一个派生类对象时，编译器检测该类型有虚函数，所以为这个派生类对象生成一个**虚函数指针**，指向该类型的虚函数表，这个虚函数指针的初始化是在构造函数中完成的。

后续如果有一个基类类型的指针指向派生类，那么当调用虚函数时，就会根据所指真正对象的虚函数表指针去寻找虚函数的地址，也就可以调用派生类的虚函数表中的虚函数，从而实现多态。

- **多态的实现原理**

多态一般就是指**继承加虚函数实现的多态**，多态可以分为静态多态和动态多态。

**静态多态**其实就是重载，静态多态在编译时期就决定了调用哪个函数，根据参数列表来决定；

**动态多态**是指通过子类重写父类的虚函数来实现的，因为是在运行期间决定调用的函数，所以称为动态多态，

一般情况下我们不区分这两个时所说的多态就是指动态多态。动态多态的实现与虚函数表，虚函数指针相关。

**静态多态**和**动态多态**区别：静态多态的函数地址早绑定 - 编译阶段确定函数地址；动态多态的函数地址晚绑定 - 运行阶段确定函数地址

**多态满足条件**：有继承关系；子类重写父类中的虚函数；

**多态使用条件**：父类指针或引用指向子类对象；

- **存放位置**

1. 虚函数表指针位置取决于对象在哪。如果是new的对象，则存在堆上，如果是直接声明，则存在栈上；

2. 虚函数表位于只读数据段（.rodata），即C++内存模型中的常量区；

3. 虚函数代码则位于代码段（.text），即C++内存模型中的代码区。

- **编译器如何建立虚函数表**

对于派生类来说，编译器建立**虚函数表**有三个步骤：

1. 拷贝基类的虚函数表，如果是多继承，就拷贝每个有虚函数基类的虚函数表；

2. 还有一个基类的虚函数表和派生类自身的虚函数表共用了一个虚函数表，称这个基类为派生类的主基类；

3. 查看派生类中是否有重写基类中的虚函数， 如果有，就替换成已经重写的虚函数地址；查看派生类是否有自身的虚函数，如果有，就追加自身的虚函数到自身的虚函数表中。

- **析构函数一般写成虚函数的原因**

为了防止内存泄漏。一个基类的指针指向一个派生类的对象，在使用完毕准备销毁时，如果基类的析构函数没有定义成虚函数，那么编译器根据指针类型就会认为当前对象的类型是基类，调用基类的析构函数 （该对象的析构函数的函数地址早就被绑定为基类的析构函数），仅执行基类的析构，派生类的自身内容将无法被析构，造成内存泄漏。

如果基类的析构函数定义成虚函数，那么编译器就可以根据实际对象，执行派生类的析构函数，再执行基类的析构函数，成功释放内存。

- **构造函数为什么一般不定义为虚函数**

而且从目前编译器通过虚函数来实现多态的方式来看，虚函数的调用是通过实例化之后对象的虚函数表指针来找到虚函数的地址进行调用的。如果构造函数是虚函数，那么虚函数表指针则是不存在的，无法找到对应的虚函数表来调用虚函数，那么这个调用实际上也是违反了先实例化后调用的准则。

调用构造函数后， 才能生成一个对象。 假设构造函数是虚函数， 虚函数存在于虚函数表中， 而去找虚函数表又需要虚函数表指针， 而虚函数表指针又存在于对象中， 这样就矛盾了： 都没有生成对象， 哪有什么虚函数表指针呢？

- **纯虚函数**

声明一个纯虚函数的目的就是为了让派生类只继承成员函数的接口，而且派生类中必需提供一个这个纯虚函数的实现，否则含有纯虚函数的类将是**抽象类**，不能进行实例化。

对于纯虚函数来说，我们其实是可以给它提供实现代码的，但是由于抽象类不能实例化，调用这个实现的唯一方式是在派生类对象中指出其 class 名称来调用。

纯虚函数语法：`virtual 返回值类型 函数名 （参数列表）= 0` ，当类中有了纯虚函数，这个类也称为抽象类。

抽象类特点：无法实例化对象；子类必须重写抽象类中的纯虚函数，否则也属于抽象类。

- **哪些函数不能是虚函数**

**构造函数**，构造函数初始化对象，派生类必须知道基类函数干了什么，才能进行构造；当有虚函数时，每一个类有一个虚函数表，每一个对象有一个虚表指针，虚表指针在构造函数中初始化；

**内联函数**，内联函数表示在编译阶段进行函数体的替换操作，而虚函数意味着在运行期间进行类型确定，所以内联函数不能是虚函数；

**静态函数**，静态函数不属于对象属于类，静态成员函数没有this指针，因此静态函数设置为虚函数没有任何意义。

**友元函数**，友元函数不属于类的成员函数，不能被继承。对于没有继承特性的函数没有虚函数的说法。

**普通函数**，普通函数不属于类的成员函数，不具有继承特性，因此普通函数没有虚函数。

- **实例化一个对象需要哪几个阶段**

**1、分配空间**

创建类对象首先要为该对象分配内存空间。不同的对象，为其分配空间的时机未必相同。全局对象、静态对象、分配在栈区域内的对象，在编译阶段进行内存分配；存储在堆空间的对象，是在运行阶段进行内存分配。

**2、初始化**

首先明确一点：初始化不同于赋值。初始化发生在赋值之前，初始化随对象的创建而进行，而赋值是在对象创建好后，为其赋上相应的值。这一点可以联想下上一个问题中提到：初始化列表先于构造函数体内的代码执行，初始化列表执行的是数据成员的初始化过程，这个可以从成员对象的构造函数被调用看的出来。

**3、赋值**

对象初始化完成后，可以对其进行赋值。对于一个类的对象，其成员变量的赋值过程发生在类的构造函数的函数体中。当执行完该函数体，也就意味着类对象的实例化过程完成了。

总结：构造函数实现了对象的初始化和赋值两个过程，对象的初始化是通过初始化列表来完成，而对象的赋值则才是通过构造函数的函数体来实现。对于拥有虚函数的类的对象，还需要给虚表指针赋值。

没有继承关系的类，分配完内存后，首先给虚表指针赋值，然后再列表初始化以及执行构造函数的函数体，即上述中的初始化和赋值操作。

有继承关系的类，分配内存之后，首先进行基类的构造过程，然后给该派生类的虚表指针赋值，最后再列表初始化以及执行构造函数的函数体，即上述中的初始化和赋值操作。

类对象的初始化顺序：**基类构造函数–>派生类成员变量的构造函数–>派生类自身构造函数**

### delete this

- 在**成员函数**中调用delete this会出现什么问题？对象还可以使用吗？

在类对象的内存空间中，只有数据成员和虚函数表指针，并不包含代码内容，类的成员函数单独放在代码段中。在调用成员函数时，隐含传递一个this指针，让成员函数知道当前是哪个对象在调用它。当调用delete this时，类对象的内存空间被释放。在delete this之后进行的其他任何函数调用，只要不涉及到this指针的内容，都能够正常运行。一旦涉及到this指针，如操作数据成员，调用虚函数等，就会出现不可预期的问题。

- 如果在类的**析构函数**中调用delete this，会发生什么？

会导致堆栈溢出。原因很简单，delete的本质是“为将被释放的内存调用一个或多个析构函数，然后，释放内存”。显然，delete this会去调用本对象的析构函数，而析构函数中又调用delete this，形成无限递归，造成堆栈溢出，系统崩溃。

### 函数模板和类模板

1. 什么是模板？如何实现？

**模板**：创建类或者函数的蓝图或者公式，分为函数模板和类模板。

**实现方式**：模板定义以关键字 **template** 开始，后跟一个模板参数列表。

- 模板参数列表不能为空；
- 模板类型参数前必须使用关键字 class 或者 typename，在模板参数列表中这两个关键字含义相同，可互换使用。

```php
template <typename T, typename U, ...>
```

函数模板：通过定义一个函数模板，可以避免为每一种类型定义一个新函数。

- 对于函数模板而言，模板类型参数可以用来指定返回类型或函数的参数类型，以及在函数体内用于变量声明或类型转换。
- 函数模板实例化：当调用一个模板时，编译器用函数实参来推断模板实参，从而使用实参的类型来确定绑定到模板参数的类型。

```php
#include<iostream>

using namespace std;

template <typename T>
T add_fun(const T & tmp1, const T & tmp2){
    return tmp1 + tmp2;
}

int main(){
    int var1, var2;
    cin >> var1 >> var2;
    cout << add_fun(var1, var2);

    double var3, var4;
    cin >> var3 >> var4;
    cout << add_fun(var3, var4);
    return 0;
}
```

类模板：类似函数模板，类模板以关键字 template 开始，后跟模板参数列表。但是，编译器不能为类模板推断模板参数类型，需要在使用该类模板时，在模板名后面的尖括号中指明类型。

```php
#include <iostream>

using namespace std;

template <typename T>
class Complex
{
public:
    //构造函数
    Complex(T a, T b)
    {
        this->a = a;
        this->b = b;
    }

    //运算符重载
    Complex<T> operator+(Complex &c)
    {
        Complex<T> tmp(this->a + c.a, this->b + c.b);
        cout << tmp.a << " " << tmp.b << endl;
        return tmp;
    }

private:
    T a;
    T b;
};

int main()
{
    Complex<int> a(10, 20);
    Complex<int> b(20, 30);
    Complex<int> c = a + b;

    return 0;
}
```

2. 函数模板和类模板的区别？

实例化方式不同：函数模板实例化由编译程序在处理函数调用时自动完成，类模板实例化需要在程序中显式指定。

实例化的结果不同：函数模板实例化后是一个函数，类模板实例化后是一个类。

默认参数：类模板在模板参数列表中可以有默认参数。

特化：函数模板只能全特化；而类模板可以全特化，也可以偏特化。

调用方式不同：函数模板可以隐式调用，也可以显式调用；类模板只能显式调用。

函数模板调用方式举例：

```php
#include<iostream>

using namespace std;

template <typename T>
T add_fun(const T & tmp1, const T & tmp2){
    return tmp1 + tmp2;
}

int main(){
    int var1, var2;
    cin >> var1 >> var2;
    cout << add_fun<int>(var1, var2); // 显式调用

    double var3, var4;
    cin >> var3 >> var4;
    cout << add_fun(var3, var4); // 隐式调用
    return 0;
}

```

3. 什么是可变参数模板？

可变参数模板：接受可变数目参数的模板函数或模板类。将可变数目的参数被称为参数包，包括模板参数包和函数参数包。

- 模板参数包：表示零个或多个模板参数；
- 函数参数包：表示零个或多个函数参数。

用省略号来指出一个模板参数或函数参数表示一个包，在模板参数列表中，class… 或 typename… 指出接下来的参数表示零个或多个类型的列表；一个类型名后面跟一个省略号表示零个或多个给定类型的非类型参数的列表。当需要知道包中有多少元素时，可以使用 sizeof… 运算符。

```cpp
template <typename T, typename... Args> // Args 是模板参数包
void foo(const T &t, const Args&... rest); // 可变参数模板，rest 是函数参数包
12
#include <iostream>

using namespace std;

template <typename T>
void print_fun(const T &t)
{
    cout << t << endl; // 最后一个元素
}

template <typename T, typename... Args>
void print_fun(const T &t, const Args &...args)
{
    cout << t << " ";
    print_fun(args...);
}

int main()
{
    print_fun("Hello", "wolrd", "!");
    return 0;
}
/*运行结果：
Hello wolrd !
*/
```

说明：可变参数函数通常是递归的，第一个版本的 print_fun 负责终止递归并打印初始调用中的最后一个实参。第二个版本的 print_fun 是可变参数版本，打印绑定到 t 的实参，并用来调用自身来打印函数参数包中的剩余值。

4. 什么是模板特化？为什么特化？

模板特化的原因：模板并非对任何模板实参都合适、都能实例化，某些情况下，通用模板的定义对特定类型不合适，可能会编译失败，或者得不到正确的结果。因此，当不希望使用模板版本时，可以定义类或者函数模板的一个特例化版本。

模板特化：模板参数在某种特定类型下的具体实现。分为函数模板特化和类模板特化

- 函数模板特化：将函数模板中的全部类型进行特例化，称为函数模板特化。
- 类模板特化：将类模板中的部分或全部类型进行特例化，称为类模板特化。

特化分为全特化和偏特化：

- 全特化：模板中的模板参数全部特例化。
- 偏特化：模板中的模板参数只确定了一部分，剩余部分需要在编译器编译时确定。

说明：要区分下函数重载与函数模板特化。定义函数模板的特化版本，本质上是接管了编译器的工作，为原函数模板定义了一个特殊实例，而不是函数重载，函数模板特化并不影响函数匹配。

```php
#include <iostream>
#include <cstring>

using namespace std;
//函数模板
template <class T>
bool compare(T t1, T t2)
{
    cout << "通用版本：";
    return t1 == t2;
}

template <> //函数模板特化
bool compare(char *t1, char *t2)
{
    cout << "特化版本：";
    return strcmp(t1, t2) == 0;
}

int main(int argc, char *argv[])
{
    char arr1[] = "hello";
    char arr2[] = "abc";
    cout << compare(123, 123) << endl;
    cout << compare(arr1, arr2) << endl;

    return 0;
}
/*
运行结果：
通用版本：1
特化版本：0
*/
```

## STL

### STL原理

STL ⼀共提供六⼤组件，包括**容器，算法，迭代器，仿函数，适配器和空间配置器**，彼此可以组合套⽤。容器通过配置器取得数据存储空间，算法通过迭代器存取容器内容，仿函数可以协助算法完成不同的策略变化，适配器可以应⽤于容器、 仿函数和迭代器。

容器：各种数据结构，如 vector，list，deque，set，map，⽤来存放数据， 从实现的⻆度来讲是⼀种类模板。

算法：是用来操作容器中的数据的模板函数，如 sort（插⼊，快排，堆排序），search（⼆分查找）， 从实现的⻆度来讲是⼀种⽅法模板。

迭代器：提供了访问容器中对象的方法。从实现的⻆度来看，迭代器是⼀种将 operator*，operator->，operator++，operator-- 等指针相关操作赋予重载的类模板，所有的 STL 容器都有⾃⼰的迭代器。

仿函数：从实现的⻆度看，仿函数是⼀种重载了 operator() 的类或者类模板，可以帮助算法实现不同的策略。

适配器：⼀种⽤来修饰容器或者仿函数或迭代器接⼝的东⻄。简单的说就是一种接口类，专门用来修改现有类的接口，提供一种新的接口，或调用现有的函数来实现所需要的功能。

空间配置器：负责空间配置与管理，从实现的⻆度讲，配置器是⼀个实现了动态空间配置、空间管理，空间释放的类模板。

### STL的两级空间配置器

首先明白为什么需要二级空间配置器？

我们知道动态开辟内存时，要在堆上申请，但若是我们需要频繁的在堆开辟释放内存，则就会在堆上造成很多外部碎片，浪费了内存空间；每次都要进行调用malloc、free函数等操作，使空间就会增加一些附加信息，降低了空间利用率；随着外部碎片增多，内存分配器在找不到合适内存情况下需要合并空闲块，浪费了时间，大大降低了效率。于是就设置了二级空间配置器，当开辟内存<=128bytes时，即视为开辟小块内存，则调用二级空间配置器。关于STL中一级空间配置器和二级空间配置器的选择上，一般默认选择的为二级空间配置器。 如果大于128字节再转去一级配置器。

**一级配置器**

**一级空间配置器**中重要的函数就是allocate、deallocate、reallocate 。 一级空间配置器是以malloc()，free()，realloc()等C函数执行实际的内存配置 。大致过程是：

1. 直接allocate分配内存，其实就是malloc来分配内存，成功则直接返回，失败就调用处理函数

2. 如果用户自定义了内存分配失败的处理函数就调用，没有的话就返回异常

3. 如果自定义了处理函数就进行处理，完事再继续分配试试

**二级适配器**

对于第⼆级配置器，如果需求块⼤⼩⼤于 128bytes，则直接转⽽调⽤第⼀级配置器，使⽤ malloc()分配内存。如果需求块⼤⼩⼩于 128bytes，第⼆级配置器中维护了 16 个⾃由链表，负责 16 种⼩型区块的次配置能⼒。

即当有⼩于 128bytes 的需求块要求时，⾸先查看所需需求块⼤⼩所对应的**链表**中是否有空闲空间，如果有则直接返回，如果没有，则向**内存池**中申请所需需求块⼤⼩的内存空间，如果申请成功，则将其加⼊到⾃由链表中。如果内存池中没有空间，则使⽤ malloc() 从**堆**中进⾏申请，且申请到的⼤⼩是需求量的⼆倍（或⼆倍＋n 附加量），⼀倍放在⾃由空间中，⼀倍（或⼀倍＋n）放⼊内存池中。

如果 malloc()也失败，则会遍历⾃由空间链表，四处寻找“尚有未⽤区块，且区块够⼤”的 freelist，找到⼀块就挖出⼀块交出。如果还是没有，仍交由 malloc()处理，因为 malloc() 有 out-of-memory 处理机制或许有机会释放其他的内存拿来⽤，如果可以就成功，如果不⾏就报 bad_alloc 异常。

STL二级空间配置器虽然解决了外部碎片与提高了效率，但它同时增加了一些缺点：

1. 因为自由链表的管理问题，它会把我们需求的内存块自动提升为8的倍数，这时若你需要1个字节，它会给你8个字节，即浪费了7个字节，所以它又引入了内部碎片的问题，若相似情况出现很多次，就会造成很多内部碎片；

2. 二级空间配置器是在堆上申请大块的狭义内存池，然后用自由链表管理，供现在使用，在程序执行过程中，它将申请的内存一块一块都挂在自由链表上，即不会还给操作系统，并且它的实现中所有成员全是静态的，所以它申请的所有内存只有在进程结束才会释放内存，还给操作系统，由此带来的问题有：

   （1）即我不断的开辟小块内存，最后整个堆上的空间都被挂在自由链表上，若我想开辟大块内存就会失败；

   （2）若自由链表上挂很多内存块没有被使用，当前进程又占着内存不释放，这时别的进程在堆上申请不到空间，也不可以使用当前进程的空闲内存，由此就会引发多种问题。

### 常见容器及其原理

容器可以用于存放各种类型的数据（基本类型的变量，对象等）的数据结构，都是模板类，分为顺序容器、关联式容器、容器适配器三种类型，三种类型容器特性分别如下：

1. 顺序式容器

   容器并非排序的，元素的插入位置同元素的值无关。包含vector、deque、list，具体实现原理如下：

   （1）vector 

   动态数组。元素在内存连续存放，随机存取任何元素都能在常数时间完成，在尾端增删元素具有较佳的性能。

   （2）deque

   双向队列。元素在内存连续存放**，**随机存取任何元素都能在常数时间完成（仅次于vector），在两端增删元素具有较佳的性能（大部分情况下是常数时间）。

   （3）list 

   双向链表。元素在**内存不连续存放**。在任何位置增删元素都能在常数时间完成，不支持随机存取。无成员函数，给定一个下标i，访问第i个元素的内容，只能从头部挨个遍历到第i个元素。

2. 关联式容器

   **元素是排序的**；插入任何元素，都按相应的排序规则来确定其位置；在查找时具有非常好的性能；通常以平衡二叉树的方式实现。包含set、multiset、map、multimap，具体实现原理如下：

   （1）set/multiset 

   set 即集合。set中不允许相同元素，multiset中允许存在相同元素。

   （2）map/multimap 

   map与set的不同在于map中存放的元素有且仅有两个成员变量，一个名为first，另一个名为second。map根据first值对元素从小到大排序，并可快速地根据first来检索元素。

   **注意**：map同multimap的不同在于是否允许存在first值相同的元素。

3. 容器适配器

   封装了一些基本的容器，使之具备了新的函数功能，比如把deque封装一下变为一个具有stack功能的数据结构。新得到的数据结构就叫适配器，包含stack, queue, priority_queue，具体实现原理如下：

   （1）stack 

   栈是项的有限序列，并满足序列中被删除、检索和修改的项只能是最近插入序列的项（栈顶的项），后进先出。

   （2）queue 

   队列。插入只可以在尾部进行，删除、检索和修改只允许从头部进行，先进先出。

   （3）priority_queue 

   优先级队列。内部维持某种有序，然后确保优先级最高的元素总是位于头部。最高优先级元素总是第一个出列。

### 迭代器

**什么是迭代器？**

Iterator（迭代器）模式又称游标（Cursor）模式，用于提供一种方法顺序访问一个聚合对象中各个元素, 而又不需暴露该对象的内部表示。 或者这样说可能更容易理解：Iterator模式是运用于聚合对象的一种模式，通过运用该模式，我们可以在不知道对象内部表示的情况下，按照一定顺序（由iterator提供的方法）访问聚合对象中的各个元素。 由于Iterator模式的以上特性：与聚合对象耦合，在一定程度上限制了它的广泛运用，一般仅用于底层聚合支持类，如STL的list、vector、stack等容器类及ostream_iterator等扩展Iterator。

```php
#include <vector>
#include <iostream>
using namespace std;

int main() {
    vector<int> v; //一个存放int元素的数组，一开始里面没有元素
    v.push_back(1);
    v.push_back(2);
    v.push_back(3);
    v.push_back(4);
    
    vector<int>::const_iterator i; //常量迭代器
    for (i = v.begin(); i != v.end(); ++i) //v.begin()表示v第一个元素迭代器指针，++i指向下一个元素
        cout << *i << ","; //*i表示迭代器指向的元素
    cout << endl;

    vector<int>::reverse_iterator r; //反向迭代器
    for (r = v.rbegin(); r != v.rend(); r++)
        cout << *r << ",";
    cout << endl;
    
    vector<int>::iterator j; //非常量迭代器
    for (j = v.begin();j != v.end();j++)
        *j = 100;
    for (i = v.begin();i != v.end();i++)
        cout << *i << ",";
    return 0;
}

/*    运行结果：
          1,2,3,4,
          4,3,2,1,
          100,100,100,100,
*/                
```

容器的`end()`方法返回一个迭代器，需要注意：这个迭代器不指向实际的元素，而是表示末端元素的下一个元素，这个迭代器起一个哨兵的作用，表示已经处理完所有的元素。因此，在查找的时候，返回的迭代器不等于`end()`，说明找到了目标；等于end()，说明检查了所有元素，没有找到目标。


**迭代器的作用**

（1）用于指向顺序容器和关联容器中的元素

（2）通过迭代器可以读取它指向的元素

（3）通过非const迭代器还可以修改其指向的元素

**迭代器和指针的区别**

迭代器不是指针，是类模板，表现的像指针。他只是模拟了指针的一些功能，重载了指针的一些操作符，–>、++、--等。迭代器封装了指针，是一个可遍历STL容器内全部或部分元素的对象，**本质**是封装了原生指针，是指针概念的一种提升，提供了比指针更高级的行为，相当于一种智能指针，他可以根据不同类型的数据结构来实现不同的++，--等操作。

迭代器返回的是对象引用而不是对象的值，所以cout只能输出迭代器使用取值后的值而不能直接输出其自身。

**迭代器产生的原因**

Iterator类的访问方式就是把不同集合类的访问逻辑抽象出来，使得不用暴露集合内部的结构而达到循环遍历集合的效果。

**迭代器什么时候会失效？迭代器如何删除元素？**

对于顺序式容器vector，deque来说，使用erase后，后边的每个元素的迭代器都会失效，后边每个元素都往前移动一位，erase返回下一个有效的迭代器。

对于关联式容器map，set来说，使用了erase后，当前元素的迭代器失效，但是其结构是**红黑树**，删除当前元素，不会影响下一个元素的迭代器，所以在调用erase之前，记录下一个元素的迭代器即可。

对于list来说，它使用了不连续分配的内存，并且它的erase方法也会返回下一个有效的迭代器，因此上面两种方法都可以使用。

|      容器      | 容器上的迭代器类别 |
| :------------: | :----------------: |
|     vector     |      随机访问      |
|     deque      |      随机访问      |
|      list      |        双向        |
|  set/multiset  |        双向        |
|  map/multimap  |        双向        |
|     stack      |    不支持迭代器    |
|     queue      |    不支持迭代器    |
| priority_queue |    不支持迭代器    |


### vector原理

Vector在堆中分配了⼀段连续的内存空间来存放元素，随着元素的加⼊，它的内部机制会⾃⾏扩充空间以容纳新元素。vector 维护的是⼀个连续的线性空间，⽽且普通指针就可以满⾜要求，能作为 vector 的迭代器。

vector 的数据结构中其实就是三个迭代器构成的，⼀个指向⽬前使⽤空间头的 iterator，⼀个指向⽬前使⽤空间尾的iterator，⼀个指向⽬前可⽤空间尾的 iterator。当有新的元素插⼊时，如果⽬前容量够⽤则直接插⼊，如果容量不够，则容量扩充⾄两倍，如果两倍容量不⾜， 就扩张⾄⾜够⼤的容量。

<div align=center><img src="https://fastly.jsdelivr.net/gh/CARLOSGP2021/myFigures/img/202206072029286.png" alt="image-20220607202913219" style="zoom:70%;" /></div>

扩充的过程并不是直接在原有空间后⾯追加容量，⽽是重新申请⼀块连续空间，将原有的数据拷⻉到新空间中，再释放原有空间，完成⼀次扩充。需要注意的是，每次扩充是重新开辟的空间，所以扩充后，原有的迭代器将会失效。

**新增元素**

Vector通过一个连续的数组存放元素，如果集合已满，在新增数据的时候，就要分配一块更大的内存，将原来的数据复制过来，释放之前的内存，再插入新增的元素。插入新数据可以通过最后插入`push_back`和通过迭代器在任何位置插入`insert()`。通过迭代器与第一个元素的距离知道要插入的位置，即`int index = iter - begin()`，这个元素后面的所有元素都向后移动一个位置，在空出来的位置上存入新增的元素。

```php
//新增元素
void insert(const_iterator iter, const T &t){
    int index = iter - begin();
    if (index < size_){
        if (size_ == capacity_){
            int capa = calculateCapacity();
            newCapacity(capa);
        }
        memmove(buf + index + 1, buf + index, (size_ - index) * sizeof(T));
        buf[index] = t;
        size_++;
    }
}
```

**删除元素**

删除也分两种：删除最后一个元素`pop_back`和通过迭代器删除任意一个元素`erase(iter)`。通过迭代器删除要先找到要删除元素的位置，即`int index = iter - begin()`，这个位置后面的每个元素都想前移动一个元素的位置。`erase`不释放内存，只初始化成默认值。

删除全部元素`clear`：只是循环调用了`erase`，所以删除全部元素的时候不释放内存，内存是在析构函数中释放的。

```php
//删除元素
iterator erase(const_iterator iter){
    int index = iter - begin();
    if (index < size_ && size_ > 0){
        memmove(buf + index, buf + index + 1, (size_ - index) * sizeof(T));
        buf[--size_] = T();
    }
    return iterator(iter);
}
```

**push_back 和 emplace_back **

如果要将一个临时变量push到容器的末尾，`push_back()`需要先构造临时对象，再将这个对象拷贝到容器的末尾，最后销毁临时对象。而`emplace_back() `会在容器中原地创建一个对象，减少临时对象拷贝、销毁的步骤，所以性能更高。

如果插入vector的类型的构造函数接受多个参数，那么push_back只能接受该类型的对象，而emplace_back还能接受该类型的构造函数的参数。如果只有一个构造参数，push_back在c++11就支持只把单个的构造参数传进去了（写法更简洁，效果、性能跟传对象是一模一样的），会进行类型自动转换。

在性能上，对于内置类型性能都一样，而对于用户自定义的类，`emplace_pack`仅在通过使用**构造参数**传入的时候更高效。

1. 若通过构造参数向vector中插入对象，emplace_back更高效：

```php
std::vector<A> a;
a.emplace_back(1);  
a.push_back(2);
```

emplace_back：仅调用有参构造函数 A (int x_arg) ；

push_back：（1）调用有参构造函数 A (int x_arg) 创建临时对象；（2）调用移动构造函数 A (A &&rhs) 到vector中；（3）调用析构函数销毁临时对象；

2. 插入临时对象，二者一样，调用移动构造函数：

```php
std::vector<A> a;
a.emplace_back(A(1)); 
a.push_back(A(2));
```

插入对象都需要三步走：建临时对象->移动->销毁临时对象

3. 插入实例化的对象，二者还是一样，调用拷贝构造函数：

```php
std::vector<A> a;
A obj(1);
a.emplace_back(obj); 
a.push_back(obj);
```

注意：这里调用的是拷贝构造函数：拷贝->销毁临时对象。

**将N个元素使用push_back插入到vector中， 求push_back操作的复杂度**。参考：[1](https://blog.csdn.net/weixin_43343803/article/details/106708543)、[2](https://blog.csdn.net/yangshiziping/article/details/52550291)

考虑vector每次内存扩充两倍的情况。如果我们插入`N`个元素， 则会引发`lgN`次的内存扩充，而每次扩充引起的元素拷贝次数分别为2^0,  2^1, 2^2, ..., 2^lgN，把所有的拷贝次数相加得到 2^0 + 2^1 + 2^2 + ... + 2^lgN = 2 * 2^lgN - 1 约为 2N次，共拷贝了N次最后一个元素，所以总的操作大概为3N。所以每个push_back操作分摊3次， 是O(1) 的复杂度。

**为什么要成倍的扩容而不是一次增加一个固定大小的容量呢？**

采用成倍方式扩容，可以保证常数的时间复杂度，而增加指定大小的容量只能达到O(n)的时间复杂度，因此使用成倍的方式扩容。

**为什么是以两倍的方式扩容而不是三倍四倍，或者其他方式呢？**

考虑可能产生的堆空间浪费，成倍增长倍数不能太大，使用较为广泛的扩容方式有两种，以2倍的方式扩容，或者以1.5倍的方式扩容。以2倍的方式扩容，下一次申请的内存必然大于之前分配内存的总和，导致之前分配的内存不能再被使用，所以最好倍增长因子设置为(1,2)之间。倍数过大容易使申请的新空间比之前已经申请的旧空间还大，导致空间的无法重复利用。

**resize和reserve**

首先必须弄清楚两个概念：

- capacity：该值在容器初始化时赋值，指的是容器能够容纳的最多的元素的个数，还不能通过下标来访问，因为此时容器中还没有创建任何对象。

- size：指的是此时容器中实际的元素个数，可以通过下标访问`0 ~ (size - 1)`范围内的对象。

resize和reserve区别主要有以下几点：

1. resize既分配了空间，也创建了对象；reserve表示容器预留空间，但没有创建对象，需要通过 insert() 或 push_back() 等创建对象。

2. resize既修改capacity大小，也修改size大小；reserve只修改capacity大小，不修改size大小。

3. 两者的形参个数不一样。 resize带两个参数，一个表示容器大小，一个表示初始值（默认为0）；reserve只带一个参数，表示容器预留空间的大小。

### deque原理

vector是单向开口（尾部）的连续线性空间，deque则是一种双向开口的连续线性空间，虽然vector也可以在头尾进行元素操作，但是其头部操作的效率十分低下（主要是涉及到整体的移动）。deque和vector的最大差异一个是deque可以在常数时间内在头端进行元素操作，二是deque没有容量的概念，它是由分段连续空间组合而成的，可以随时增加一段新的空间并链接起来。

deque虽然也提供随机访问的迭代器，但是其迭代器并不是普通的指针，其复杂程度比vector高很多，因此除非必要，否则一般使用vector而非deque。如果需要对deque排序，可以先将deque中的元素复制到vector中，利用sort对vector排序，再将结果复制回deque。

deque由一段一段的定量连续空间组成，一旦需要增加新的空间，只要配置一段定量连续空间拼接在头部或尾部即可，因此deque的最大任务是如何维护这个整体的连续性。

deque的数据结构如下：

```php
class deque{
    ...
protected:
    typedef pointer* map_pointer;//指向map指针的指针
    map_pointer map;			//指向map
    size_type map_size;			//map的大小
public:
    ...
    iterator begin();
    itertator end();
    ...
}
```

<div align=center><img src="https://fastly.jsdelivr.net/gh/CARLOSGP2021/myFigures/img/202206082031596.png" alt="image-20220608203058478" style="zoom:90%;" /></div>

deque内部有一个指针指向map，map是一小块连续空间，其中的每个元素称为一个节点node，每个node都是一个指针，指向另一段较大的连续空间，称为**缓冲区**，这里就是deque中实际存放数据的区域，默认大小为512bytes。

deque的迭代器数据结构如下：

```php
struct __deque_iterator{
    ...
    T* cur;		//迭代器所指缓冲区当前的元素
    T* first;	//迭代器所指缓冲区第一个元素
    T* last;	//迭代器所指缓冲区最后一个元素
    map_pointer node;	//指向map中的node
    ...
}    
```

从deque的迭代器数据结构可以看出，为了保持与容器联结，迭代器主要包含上述4个元素。

<div align=center><img src="https://fastly.jsdelivr.net/gh/CARLOSGP2021/myFigures/img/202206082033790.png" alt="image-20220608203356715" style="zoom:80%;" /></div>

deque迭代器的“++”、“--”操作是远比vector迭代器繁琐，其主要工作在于缓冲区边界，如何从当前缓冲区跳到另一个缓冲区。当然deque内部在插入元素时，如果map中node数量全部使用完，且node指向的缓冲区也没有多余的空间，这时会配置新的map（2倍于当前+2的数量）来容纳更多的node，也就是可以指向更多的缓冲区。在deque删除元素时，也提供了元素的析构和空闲缓冲区空间的释放等机制。


### list原理

相比于vector的连续线型空间，list显得复杂许多，它的好处在于插入或删除都只作用于一个元素空间，因此list对空间的运用是十分精准的，对任何位置元素的插入和删除都是常数时间。list不能保证节点在存储空间中连续存储，也拥有迭代器，迭代器的“++”、“--”操作是指针操作，list提供的迭代器类型是双向迭代器。

list节点的结构见如下源码：

```php
template <class T>
struct __list_node{
    typedef void* void_pointer;
    void_pointer prev;
    void_pointer next;
    T data;
}
```

从源码可看出list显然是一个双向链表。list与vector的另一个区别是，list在插入和接合操作之后，都不会造成原迭代器失效，而vector可能因为空间重新配置导致迭代器失效。

此外list也是一个环形链表，因此只要一个指针便能完整遍历整个链表。list中node节点指针始终指向尾端的一个空白节点，因此是一种“前闭后开”的区间结构。

list的空间管理默认采用alloc作为空间配置器，为了方便以节点大小为配置单位，还定义一个`list_node_allocator`函数一次性配置多个节点空间。

由于list的双向特性，支持在头部和尾部两个方向进行push和pop操作，当然还支持erase，splice，sort，merge，reverse等操作。

### vector 和 list 对比

**vector：一维数组**

动态数组，元素在内存中连续存放，随机访问任何元素都在常数时间内完成，在尾端增删元素性能较好。

特点：元素在内存连续存放，动态数组，在堆中分配内存，元素连续存放，有保留内存，如果减少大小后内存也不会释放。

优点：和数组类似开辟一段连续的空间，并且支持随机访问，所以它的查找效率高其时间复杂度O(1)。

缺点：由于开辟一段连续的空间，所以插入删除会需要对数据进行移动比较麻烦，时间复杂度O(n)，另外当空间不足时还需要进行扩容。

**list：双向链表**

双向链表，元素在内存不连续存放，在任何位置增删元素都能在常数时间完成，不支持随机访问。

特点：元素在堆中存放，每个元素都是存放在一块内存中，它的内存空间可以是不连续的，通过指针来进行数据的访问。

优点：底层实现是循环双链表，当对大量数据进行插入删除时，其时间复杂度O(1)。

缺点：底层没有连续的空间，只能通过指针来访问，所以查找数据需要遍历其时间复杂度O(n)，没有提供[]操作符的重载。

**应用场景**

vector拥有一段连续的内存空间，因此支持随机访问，如果需要高效的随机访问，而不在乎插入和删除的效率，使用vector。

list拥有一段不连续的内存空间，如果需要高效的插入和删除，而不关心随机访问，则应使用list。

**删除末尾的元素，指针和迭代器如何变化？删除中间的元素呢？**

对于vector而言，删除某个元素以后，该元素后边的每个元素的迭代器都会失效，后边每个元素都往前移动一位，erase返回下一个有效的迭代器。而对于list而言，删除某个元素，只有指向被删除元素的那个迭代器失效，其它迭代器不受任何影响。

### map和unordered_map

**内部实现机理**

`map`底层是**红黑树**，内部的元素是**有序的**。map中的元素是按照**二叉树搜索树**存储的，特点就是左子树上所有节点的键值都小于根节点的键值，右子树所有节点的键值都大于根节点的键值，使用中序遍历可将键值按照从小到大遍历出来。

`unordered_map`底层是**哈希表**，内部的元素是**无序的**。哈希表采用了**函数映射**将存储位置与记录的关键字关联起来，从而实现快速查找。

**优缺点以及使用场景**

**map**

优点：`map`底层是**红黑树**，内部的元素是**有序的**，查找、增删操作都可以在`O(lgn)`的时间复杂度下完成，因此效率非常的高。

缺点：空间占用率高，因为map内部实现了红黑树，虽然提高了运行效率，但是因为每一个节点都需要额外保存父节点，孩子节点以及红黑性质，使得每一个节点都占用大量的空间。

适用：有顺序要求的问题，用map会更高效一些。

**unordered_map**

优点：底层是哈希表，查找速度非常的快。

缺点：哈希表的建立比较耗费时间。

适用：对于查找问题，unordered_map会更加高效一些，因此遇到查找问题，常会考虑用unordered_map。

对于unordered_map或者unordered_set容器，其遍历顺序与创建该容器时输入元素的顺序是不一定一致的，遍历是按照**哈希表**从前往后依次遍历的。

**map下标操作 [ ] 和insert的区别**

**insert**

insert 含义是：在 map 中，如果key存在，则插入失败；如果key不存在，就创建这个key－value。实例: `map.insert((key, value))`。insert接受一个pair参数，并且返回值也是一个pair。

返回值pair中：

第一个元素是一个迭代器，如果数据插入成功，则指向插入关键字的位置，用->解引用可以提取pair类型元素； 若插入失败，迭代器指向已经存在的该元素的位置。

第二个元素是一个bool类型变量，如果关键字已在map中，insert什么也不做，second返回false，插入失败；如果关键字不存在，元素被插入，second返回true。

**下标操作 [ ]**

利用下标操作的含义是：如果key存在，就更新value；如果key不存在，就创建这个key－value对。实例：`map[key] = value`。

### 哈希冲突

对于不同的关键字，可能得到同一个哈希地址，这种现象称之为**哈希冲突**，也叫哈希碰撞。

**如何减少哈希冲突？**

**一个好的哈希函数可以有效的减少哈希冲突的出现**，那什么样的哈希函数才是一个好的哈希函数呢？通常来说，一个好的哈希函数对于关键字集合中的任意一个关键字，经过这个函数映射到地址集合中任何一个集合的概率是相等的。

常用的构造哈希函数的方法有以下几种：

1. 除留取余法：关键字key除以某个不大于哈希表长m的数p，所得余数为哈希地址。即：`f(key) = key % p, p ≤ m`；

2. 直接定址法：取关键字或关键字的某个线性函数值为哈希地址。即： `f(key) = key` 或者 `f(key) = a * key + b`；

3. 数字分析法：假设关键字是以r为基的数（如以10为基的十进制数），并且哈希表中可能出现的关键字都是事先知道的，则可以选取关键字的若干位数组成哈希表。

**如何处理哈希冲突？**

虽然我们可以通过选取好的哈希函数来减少哈希冲突，但是哈希冲突终究是避免不了的。那么，碰到哈希冲突应该怎么处理呢？

1. 链地址法：在碰到哈希冲突的时候，将冲突的元素以链表的形式进行存储，也就是哈希地址相同的元素都插入到同一个链表中，元素插入的位置可以是表头（头插法），也可以是表尾（尾插法）。

2. 开放定址法：当发生地址冲突时，按照某种方法继续探测哈希表中的其他存储单元，直到找到空位置为止。

3. 再哈希法：选取若干个不同的哈希函数，在产生哈希冲突的时候计算另一个哈希函数，直到不再发生冲突为止。

4. 建立公共溢出区：专门维护一个溢出表，当发生哈希冲突时，将值填入溢出表中。

其中比较常用的是**链地址法**，比如HashMap就是基于链地址法的哈希表结构，所以unordered_map使用**开链法**解决哈希冲突。

但当链表过长时，哈希表就会退化成一个链表，查找某个元素的时间复杂度又变回了O(n)。因此，当哈希表中的链表过长时就需要我们对其进行优化。二叉搜索树的查询效率是远远高于链表的。因此，当哈希表中的链表过长时，可以把这个链表变成一棵**红黑树**。红黑树是一个可以自平衡的二叉搜索树，查询的时间复杂度为`O(lgn)`，通过这样的优化可以提高哈希表的查询效率。

### map和set

**参考回答**

1. set是一种关联式容器，其特性如下：

   （1）以红黑树作为底层容器，所有的元素都会被自动排序

   （2）元素只有key没有value，value就是key

   （3）不允许出现键值重复

   （4）不能通过迭代器来改变set的值，因为set的键值就是关键字，set的迭代器是const的

2. map和set一样是关联式容器，其特性如下：

   （1）map以红黑树作为底层容器，所有元素是通过键进行自动排序的

   （2）所有元素都是键+值存在

   （3）不允许键重复

   （4）map的键是不能修改的，但是其键对应的值是可以修改的

   综上所述，map和set**底层实现**都是红黑树；map和set的**区别**在于map的值不作为键，键和值是分开的。

### AVL树、红黑树、B+树

**二叉搜索树**

**二叉搜索树**的特点是一个节点的左子树的所有节点的值都小于这个节点，右子树的所有节点的值都大于这个节点。但是当每次插入的元素都是二叉搜索树中最大的元素，就会退化成了一条链表，查找数据的时间复杂度变成了 O(n)。

**AVL树**

为了解决二叉搜索树在极端情况下退化成链表的问题，**平衡二叉搜索树（AVL 树）**在二叉搜索树的基础上增加了一些条件约束：**每个节点的左子树和右子树的高度差不能超过 1**，一般是用平衡因子差值判断是否平衡并通过旋转来实现平衡。也就是说节点的左子树和右子树仍然为平衡二叉树，这样查询操作的时间复杂度就会一直维持在 `O(logn)` 。

不管我们是执行插入还是删除操作，只要不满足上面的条件，就要通过旋转来保持平衡，而旋转是十分耗时的，AVL树适合用于插入与删除次数比较少，但查找多的情况。

**红黑树**

除了平衡二叉搜索树，还有很多自平衡的二叉树，比如**红黑树**，它也是通过一些约束条件来达到自平衡。

红黑树也是一种二叉搜索树，红黑树每一个结点都会额外记录结点的颜色，红色或者黑色。通过对任何一条从根节点到叶子节点的路径上各个结点颜色的限制，**红黑树确保没有一条路径会比其他路径长两倍，因此，红黑树是一种弱平衡树。** 对于要求严格的AVL树来说，红黑树为了保持平衡旋转的次数较少，所以对于搜索、插入、删除操作较多的情况下，红黑树的综合能力较好。

红黑树是一种含有红黑结点并能自平衡的二叉搜索树，它必须满足下面性质：

- 性质1：每个结点要么是红色，要么是黑色
- 性质2：根节点是黑色
- 性质3：叶子结点都是黑色
- 性质4：每个红色结点的子结点一定都是黑色
- 性质5：任意一个结点到每个叶子结点的路径包含数量相同的黑色结点。

**红黑树的应用**：

1、广泛用于C++的STL中；

2、著名的Linux的的进程调度完全公平调度程序，用红黑树管理进程控制块，进程的虚拟内存区域都存储在一颗红黑树上，每个虚拟地址区域都对应红黑树的一个节点，左指针指向相邻的地址虚拟存储区域，右指针指向相邻的高地址虚拟地址空间;

3、IO多路复用的`epoll`的实现采用红黑树组织管理的的的sockfd，支持快速的增删改查;

**红黑树与AVL树的区别**：

1、红黑树不追求完全平衡，即不像AVL树那样要求平衡因子小于1，红黑树用非严格的平衡来换取旋转次数的降低，任何不平衡都会在三次旋转之内解决，而AVL树的旋转的量级为O(logn)。

2、AVL树的结构相较于红黑树更为平衡，插入和删除会引起失衡，红黑树恢复平衡效率更高；当然，由于AVL高度平衡，因此AVL的查询效率更高。

总结： 红黑树是一种弱平衡二叉搜索树（红黑树确保没有一条路径比其它路径长出两倍），在相同的节点情况下，AVL树的高度低于红黑树，相对于要求严格的AVL树来说，红黑树的旋转次数少，所以对于插入与删除较多的情况，红黑树的综合能力较好。由于AVL树高度平衡，因此AVL树的查询效率更高。

**B+树**

自平衡二叉树虽然能保持查询操作的时间复杂度在O(logn)，但是本质上是一个二叉树，每个节点只能有 2 个子节点，那么当节点个数多的时候，树的高度也会相应变高，这样就会增加磁盘的 I/O 次数，从而影响数据查询的效率。

为了解决降低树的高度的问题，后面就出来了 **B 树**，它不再限制一个节点就只能有 2 个子节点，而是允许 M 个子节点 (M>2)，从而降低树的高度。

B+ 树就是对 B 树做了一个升级，MySQL 中索引的数据结构就是采用了 B+ 树。B+ 树与 B 树的差异主要有：

![图片](https://fastly.jsdelivr.net/gh/CARLOSGP2021/myFigures/img/202206012015597.png)

- 叶子节点（最底部的节点）才会存放实际数据（索引+记录），非叶子节点只会存放索引；
- 所有索引都会在叶子节点出现，叶子节点之间构成一个有序链表；
- 非叶子节点的索引也会同时存在于子节点中，并且是子节点中所有索引的最大（或最小）值；
- 非叶子节点中有多少个子节点，就有多少个索引；

MySQL 默认的存储引擎 InnoDB 采用 B+ 树作为索引的数据结构，原因有：

- B+ 树的非叶子节点不存放实际的记录数据，仅存放索引，因此数据量相同的情况下，相比于同时存储索引和数据的 B 树来说，B+树的非叶子节点可以存放更多的索引，因此 B+ 树可以比 B 树更「矮胖」，查询底层节点的磁盘 I/O 次数会更少。
- B+ 树有大量的冗余节点（所有非叶子节点都是冗余索引），这些冗余索引让 B+ 树插入、删除的效率都更高，比如删除根节点的时候，不会像 B 树那样会发生复杂的树的变化；
- B+ 树叶子节点之间用链表连接了起来，有利于范围查询，而 B 树要实现范围查询，只能通过树的遍历来完成，这会涉及多个节点的磁盘 I/O 操作，范围查询效率不如 B+ 树。

### 容器适配器

标准库提供了三种顺序容器适配器：`queue`(FIFO队列)、`priority_queue`(优先级队列)、`stack`(栈)。

适配器对容器进行包装，使其表现出另外一种行为。例如，`stack<int, vector<int>>` 实现了栈的功能，但其内部使用顺序容器`vector<int>`来存储数据 ，相当于是`vector<int>`表现出了栈的行为。

堆建⽴在完全⼆叉树上，分为⼤根堆、⼩根堆。其在STL中做priority_queue的助⼿，即以任何顺序将元素推⼊容器中，然后取出时⼀定是从优先权最⾼的元素开始取，完全⼆叉树具有这样的性质，适合做priority_queue的底层。

优先级队列默认使用`vector`作为其底层存储数据的容器，在vector上又使用了**堆算法**将vector中元素构造成堆的结构，因此priority_queue就是堆，所有需要用到堆的位置，都可以考虑使用priority_queue，默认情况下priority_queue是最大堆。

### stack和queue原理

**stack**（栈）是一种先进后出的数据结构，只有一个入口和出口，那就是栈顶，除了获取栈顶元素外，没有其他方法可以获取到内部的其他元素。stack这种单向开口的数据结构很容易由双向开口的`deque`或者`list`形成，只需要根据stack的性质对应移除某些接口即可实现，stack的源码如下：

```php
template <class T, class Sequence = deque<T>>
class stack{
	...
protected:
    Sequence c;
public:
    bool empty(){return c.empty();}
    size_type size() const{return c.size();}
    reference top() const {return c.back();}
    const_reference top() const{return c.back();}
    void push(const value_type& x){c.push_back(x);}
    void pop(){c.pop_back();}
};
```

从stack的数据结构可以看出，其所有操作都是围绕Sequence完成，而Sequence**默认是deque数据结构**。stack修改某种接口来实现栈的操作，成为容器适配器。

stack除了默认使用deque作为其底层容器之外，也可以使用双向开口的list，只需要在初始化stack时，将list作为第二个参数即可。由于stack只能操作顶端的元素，因此其内部元素无法被访问，也不提供迭代器。

**queue**（队列）是一种先进先出的数据结构，只有一个入口和一个出口，分别位于最底端和最顶端。除了出口元素外，没有其他方法可以获取到内部的其他元素。

类似的，queue这种先进先出的数据结构很容易由双向开口的`deque`或者`list`形成，只需要根据queue的性质对应移除某些接口即可实现，queue的源码如下：

```php
template <class T, class Sequence = deque<T>>
class queue{
	...
protected:
    Sequence c;
public:
    bool empty(){return c.empty();}
    size_type size() const{return c.size();}
    reference front() const {return c.front();}
    const_reference front() const{return c.front();}
    void push(const value_type& x){c.push_back(x);}
    void pop(){c.pop_front();}
};
```

从queue的数据结构可以看出，其所有操作都也都是是围绕Sequence完成，Sequence**默认也是deque数据结构**。同样，queue也可以使用list作为底层容器，不具有遍历功能，没有迭代器。

### heap原理

heap（堆）并不是STL的容器组件，是`priority_queue`的底层实现机制，因为大根堆总是最大值位于堆的根部，优先级最高。

**二叉堆本质是一种完全二叉树**，二叉树除了最底层的叶子节点之外，都是填满的，但是叶节点从左到右不会出现空隙。

完全二叉树内没有任何节点漏洞，是非常紧凑的，这样的一个好处是可以使用数组来存储所有的节点，因为当其中某个节点位于`i`处，其左节点必定位于`2i`处，右节点位于`2i + 1`处，父节点位于`i / 2`（向下取整）处。这种以数组表示二叉树的方式称为隐式表述法。

因此我们可以使用一个数组和一组堆算法来实现最大堆（每个节点的值大于等于其子节点的值）和最小堆（每个节点的值小于等于其子节点的值）。由于数组不能动态的改变空间大小，用vector代替数组是一个不错的选择。

那heap算法有哪些？常见有的插入、弹出、排序和构造算法：

**push_heap插入算法**

由于完全二叉树的性质，新插入的元素一定是位于树的最底层作为叶子节点，并填补由左至右的第一个空格。事实上，在刚执行插入操作时，新元素位于底层`vector`的`end()`处，之后是上溯的过程。

![image-20220611113511261](https://fastly.jsdelivr.net/gh/CARLOSGP2021/myFigures/img/202206111135337.png)

新元素50在插入堆中后，先放在vector的end()存着，之后执行上溯过程，调整其根结点的位置，以便满足大根堆的性质。

**pop_heap算法**

堆的pop操作实际弹出的是根节点，在堆内部执行pop_heap时，只是将其移动到vector的最后位置，然后再为这个被挤走的元素找到一个合适的安放位置，使整颗二叉树满足完全二叉树的条件。这个被挤掉的元素首先会与根结点的两个子节点比较，并与较大的子节点更换位置，如此一直往下，直到这个被挤掉的元素大于左右两个子节点，或者下放到叶子节点为止，这个过程称为下溯。

<div align=center><img src="https://fastly.jsdelivr.net/gh/CARLOSGP2021/myFigures/img/202206111132314.png" alt="image-20220611113159174" style="zoom:85%;" /></div>

根节点68被pop之后，移到了vector的最底部，将24挤出，24被迫从根节点开始与其子节点进行比较，直到找到合适的位置安身，需要注意的是pop之后元素并没有被移走，如果要将其移走，可以使用pop_back()。

**sort算法**

因为pop_heap可以将当前heap中的最大值置于底层容器vector的末尾，heap范围减1，那么不断的执行pop_heap直到树为空，即可得到一个递增序列。

**make_heap算法**

将一段数据转化为heap，一个一个数据插入，调用上面说的两种percolate算法即可。

### priority_queue原理

priority_queue（优先级队列）是一个拥有权值观念的queue，它跟queue一样是顶部入口，底部出口，在插入元素时，元素并非按照插入次序排列，它会自动根据权值（通常是元素的实值）排列，权值最高，排在最前面。

默认情况下，priority_queue使用一个大根堆完成，底层容器使用的是一般为vector，堆heap为处理规则来管理底层容器实现。

priority_queue的这种实现机制导致其不被归为容器，而是一种容器配接器。关键的源码如下：

```php
template <class T, class Squence = vector<T>, 
class Compare = less<typename Sequence::value_tyoe>>
class priority_queue{
	...
protected:
    Sequence c; 	// 底层容器
    Compare comp; 	// 元素大小比较标准
public:
    bool empty() const {return c.empty();}
    size_type size() const {return c.size();}
    const_reference top() const {return c.front()}
    void push(const value_type& x){
        c.push_heap(x);
        push_heap(c.begin(), c.end(), comp);
    }
    void pop(){
        pop_heap(c.begin(), c.end(), comp);
        c.pop_back();
    }
};
```

priority_queue的所有元素，进出都有一定的规则，只有queue顶端的元素（权值最高者），才有机会被外界取用，它没有遍历功能，也不提供迭代器。

# 计算机网络

## 复习指南

**应用层** 

（1）另一个最最最常问的问题，在浏览器中输入 URL 地址到浏览器显示网页这个过程中计算机网络做了什么。

这个问题无论是考研还是找工作都是常见的，建议把 JavaGuide 中这个问题的总结熟读并全文背诵。

（2）HTTP 1.0 和 HTTP 1.1 的主要区别这个也要了解一下。

（3）HTTP 和 HTTPS 的区别这个也是面试常考问题，这个问题展开以后能问的就比较多了。

在回答这个问题时你首先分别介绍一下**HTTP 和 HTTPS 的原理以及区别**。大致就是 HTTP 是通过明文在网络上传输的，HTTPS 是加密的。有的面试官问到这也就可以了，有的面试官不讲武德，想搞偷袭，会继续让你讲 **HTTPS 建立连接的流程**、然后会继续追着你问**SSL 的工作流程**。建议把这里好好准备一下，面试官一问你就可以展开讲，你就能消耗很多面试时间，这样面试官问其它问题的时间就少了，嘿嘿。

（4）HTTP请求常见的状态码背几个常用的就好。

（5）DNS域名系统这里你要可以描述清楚工作原理，也是面试常问问题。

**传输层**

面试中计算机网络的问题最常出现在这一章中。

1. 记清楚 TCP 和 UDP 的区别。
2. TCP三次握手和UDP四次挥手。

这是面试计算机网络最最最常问的问题！！！你计算机网络就算其它的什么也不会，这个问题你必须要记清楚，如果面试官问出你这个问题你都答不上，面试官估计觉得你连敷衍都不想敷衍他了。

当面试官问你三次握手和四次挥手时，你要答出这三个点来：

（1）为什么要三次挥手和四次挥手，如果不这样做会有什么影响。

（2）三次握手四次挥手的整个流程。

（3）有的面试官只要你答出三次握手和四次挥手的大体流程就好了，但是有的面试官会要求你答出三次握手和四次挥手时发送端和接收端分别发了哪些标记。

3. TCP协议如何保证可靠传输

把 ARQ 协议、滑动窗口、流量控制、拥塞控制等回答清楚就算到位了。

**网络层**

网络层面试问的也相对较少，主要就是问IPV4，偶尔问一下ARP地址解析协议的的工作原理。

1. 首先要记清楚 IPV4 地址是怎么分类的、以及地址的格式。这里经常结合代码题一起问你，我和很多同学都在面试中被面试官要求写一个程序判断给定的字符串是否是 IPV4 地址。
2. IPV4 子网划分面试中不怎么问，笔试题时经常有这个问题。
3. 了解 IP 地址和 Mac 地址的区别，了解 ARP 地址解析协议并了解其工作原理。

**网络接口层**

把网卡、网桥、交换机的概念、用途简单了解下就好，一般面试官不会问。

## 键入网址到网页显示，期间发生了什么？

1. 浏览器解析`url`；
2. 生成一个`http`请求协议包，把协议包的发送委托给操作系统；
3. 操作系统在发送协议包之前先要获取服务器的IP地址。如果在本地的浏览器缓存、操作系统缓存或者hosts文件中存在对应的IP地址，就不需要再访问本地的DNS服务器了。如果不存在，访问本地的DNS服务器，由本地DNS服务器对进行递归访问，即按照层级向下访问，最后得到IP地址；
4. 得到ip地址后。进行TCP连接，三次握手；
5. 握手之后，把请求层层封装，通过网卡将数据发送到交换机。交换机会进行校验以及查找交换表转发，到达路由器。路由器把MAC层扒皮，查看目的ip，然后根据路由表选择下一跳，再进行MAC层封装。重复这个过程，最后到达服务器；
6. 到达服务器后，会对数据包进行扒皮并且校验。使用FCS校验码校验二进制序列的正确性。在MAC层看目的MAC是不是自己，在网络层看目的ip是不是自己，同时知道上层协议是TCP还是UDP协议。在TCP中知道这是一个什么保文，请求保文、响应报文还是结束连接的报文。通过端口号知道这是交给那么应用进程的；
7. 应用进程知道你访问的是什么资源，那么就给客户端返回一个Http响应协议包，把资源封装在其中。通过同样的流程把数据返回给客户端；
8. 浏览器拿到数据后，对数据进行渲染，解码，变成了一个页面显示在浏览器上。

## HTTP状态码

<div align=center><img src="https://cdn.jsdelivr.net/gh/CARLOSGP2021/myFigures/img/202205101656585.png" alt=" 五大类 HTTP 状态码 " style="zoom:50%;" /></div>

`1xx` 类状态码属于**提示信息**，是协议处理中的一种中间状态，实际用到的比较少。

`2xx` 类状态码表示服务器**成功**处理了客户端的请求，也是我们最愿意看到的状态。

- 「**200 OK**」是最常见的成功状态码，表示一切正常。如果是非 `HEAD` 请求，服务器返回的响应头都会有 body 数据。
- 「**204 No Content**」也是常见的成功状态码，与 200 OK 基本相同，但响应头没有 body 数据。
- 「**206 Partial Content**」是应用于 HTTP 分块下载或断点续传，表示响应返回的 body 数据并不是资源的全部，而是其中的一部分，也是服务器处理成功的状态。

`3xx` 类状态码表示客户端请求的资源发生了变动，需要客户端用新的 URL 重新发送请求获取资源，也就是**重定向**。

- 「**301 Moved Permanently**」表示永久重定向，说明请求的资源已经不存在了，需改用新的 URL 再次访问。
- 「**302 Found**」表示临时重定向，说明请求的资源还在，但暂时需要用另一个 URL 来访问。

301 和 302 都会在响应头里使用字段 `Location`，指明后续要跳转的 URL，浏览器会自动重定向新的 URL。

- 「**304 Not Modified**」不具有跳转的含义，表示资源未修改，重定向已存在的缓冲文件，也称缓存重定向，也就是告诉客户端可以继续使用缓存资源，用于缓存控制。

`4xx` 类状态码表示客户端发送的**报文有误**，服务器无法处理，也就是错误码的含义。

- 「**400 Bad Request**」表示客户端请求的报文有错误，但只是个笼统的错误。
- 「**403 Forbidden**」表示服务器禁止访问资源，并不是客户端的请求出错。
- 「**404 Not Found**」表示请求的资源在服务器上不存在或未找到，所以无法提供给客户端。

`5xx` 类状态码表示客户端请求报文正确，但是**服务器处理时内部发生了错误**，属于服务器端的错误码。

- 「**500 Internal Server Error**」与 400 类型，是个笼统通用的错误码，服务器发生了什么错误，我们并不知道。
- 「**501 Not Implemented**」表示客户端请求的功能还不支持，类似“即将开业，敬请期待”的意思。
- 「**502 Bad Gateway**」通常是服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问后端服务器发生了错误。
- 「**503 Service Unavailable**」表示服务器当前很忙，暂时无法响应客户端，类似“网络服务正忙，请稍后重试”的意思。

## GET和POST的区别

GET和POST是HTTP协议中的两种发送请求的方法。GET和POST本质上就是TCP链接，并无差别。但是由于HTTP的规定和浏览器/服务器处理数据能力的限制，导致他们在应用过程中体现出一些不同。

首先，HTTP对GET和POST参数的传送渠道（url还是requrest body）提出了要求：GET把参数包含在**URL**中，POST通过**消息体**传递参数。GET主要是用来获取新的网页；POST用作向服务器传递用户的表单数据，如用户名、密码、留言等等。

其次，GET和POST参数大小的限制不同：GET请求在URL中传送的参数是有长度限制的，而POST通过**消息体**传递的参数没有长度限制。

此外，GET和POST还有一个**重大区别**：GET产生一个TCP数据包，而POST产生两个TCP数据包。

对于GET请求，浏览器会把请求头和消息体一并发送出去，服务器响应200 ok（返回数据）；而对于POST请求，浏览器先发送请求头，服务器响应100 continue后，浏览器再发送消息体，服务器响应200 ok（返回数据）。

其他的区别：GET请求参数会被完整保留在浏览器历史记录里，而POST中的参数不会被保留；对参数的数据类型，GET只接受ASCII字符，而POST没有限制。

------

POST需要两步，时间上消耗的要多一点，看起来GET比POST更有效，因此Yahoo团队有推荐用GET替换POST来优化网站性能。但这是一个坑！跳入需谨慎。为什么？

1. GET与POST都有自己的语义，不能随便混用。
2. 据研究，在网络环境好的情况下，发一次包的时间和发两次包的时间差别基本可以无视。而在网络环境差的情况下，两次包的TCP在验证数据包完整性上，有非常大的优点。
3. 并不是所有浏览器都会在POST中发送两次包，Firefox就只发送一次。

[GET和POST两种基本请求方法的区别 - 在途中# - 博客园 (cnblogs.com)](https://www.cnblogs.com/logsharing/p/8448446.html)

## HTTP（1.1）特性

### 优缺点

- **优点**

1. **简单**

HTTP 基本的报文格式就是 `header + body`，头部信息也是 `key-value` 简单文本的形式，很简单。

2. **灵活和易于扩展**

HTTP协议里的各类请求方法、状态码、头字段等都是可以自定义扩展的；同时 HTTP 工作在应用层，下层可以随意变化。

3. **应用广泛和跨平台**

- **缺点**

1. **无状态**

服务器不会去记忆 HTTP 的状态，所以不需要额外的资源来记录状态信息，但是会导致它在完成有关联性的操作时会非常麻烦。例如登录->添加购物车->下单->结算->支付，这系列操作都要知道用户的身份才行。 但服务器不知道这些请求是有关联的，每次都要问一遍身份信息。

无状态的问题解决方法有`cookie/session/token`，`Cookie` 通过在请求和响应报文中写入 Cookie 信息来控制客户端的状态。

2. **明文传输**

明文意味着在传输过程中的信息是可阅读的， 通过F12 控制台或 Wireshark 抓包都可以直接查看， 方便调试，但是也导致了信息泄露。明文传输的问题在`https`协议中得到了解决。

3. **不安全**

HTTP 比较严重的缺点就是不安全：通信使用明文传输，内容可能会被窃听；不验证通信方的身份，因此有可能遭遇伪装； 无法证明报文的完整性，所以有可能已遭篡改。

HTTP 的安全问题，可以用 `HTTPS`的方式解决，也就是通过引入 SSL/TLS 层，使得在安全上达到了极致。

### 性能

1. **长连接**

> `HTTP/1.0` 规定浏览器与服务器只保持短暂的连接，浏览器的每次请求都需要与服务器建立一个TCP连接，服务器完成请求处理后立即断开TCP连接，每个TCP连接只能发送一个请求。发送数据完毕，连接就关闭，如果还要请求其他资源，就必须再新建一个连接。 TCP连接的建立需要三次握手，通信开销比较大。所以，HTTP/1.0版本的性能比较差。

为了解决上述 TCP 连接问题，`HTTP/1.1`提出了**长连接**的通信方式，也叫持久连接。这种方式的好处在于减少了 TCP 连接的重复建立和断开所造成的额外开销，减轻了服务器的负载。

持久连接的特点是，只要任意一端没有明确提出断开连接，则保持 TCP 连接状态。当然，如果某个 HTTP 长连接超过一定时间没有任何数据交互，服务端就会主动断开这个连接。

- **管道网络传输**

HTTP/1.1 采用了长连接的方式，这使得**管道网络传输**成为了可能。即可在同一个 TCP 连接里面，客户端可以发起多个请求，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以**减少整体的响应时间**。

但是服务器必须按照接收请求的顺序发送对这些管道化请求的响应，如果服务端在处理 A 请求时耗时比较长，那么后续的请求的处理都会被阻塞，造成「**队头阻塞**」。所以，**HTTP/1.1 管道解决了请求的队头阻塞，但是没有解决响应的队头阻塞**。

- **队头阻塞**

当顺序发送的请求序列中的一个请求因为某种原因被阻塞时，在后面排队的所有请求也一同被阻塞了，会招致客户端一直请求不到数据，这也就是「**队头阻塞**」。

##  HTTPS特性

### HTTP 与 HTTPS 有哪些区别？

1. HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP 网络层之间加入了 `SSL/TLS` 安全协议，使得报文能够加密传输。
2. HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 `SSL/TLS` 的握手过程，才可进入加密报文传输。
3. HTTP 的端口号是 80，HTTPS 的端口号是 443。
4. HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。

### HTTPS 如何解决HHTP的三个安全风险？

1. **混合加密**的方式实现信息的**机密性**，解决了**窃听**的风险；
2. 将服务器公钥放入到**数字证书**中，解决了**冒充**的风险；
3. **摘要算法**的方式来实现**完整性**，它能够为数据生成独一无二的「**指纹**」，指纹用于校验数据的完整性，解决了**篡改**的风险。

HTTPS 采用的是**对称加密**和**非对称加密**结合的「混合加密」方式：

- 在通信建立前采用**非对称加密**的方式交换「会话秘钥」，保证传输过程的安全性。
- 在通信过程中全部使用**对称加密**的「会话秘钥」的方式加密明文数据，保证通信过程的效率。

采用「混合加密」的方式的原因：

- **对称加密**只使用一个密钥，运算速度快，密钥必须保密，无法做到安全的密钥交换。
- **非对称加密**使用两个密钥：公钥和私钥，公钥可以任意分发而私钥保密，解决了密钥交换问题但速度慢。

### HTTPS 的优缺点

- 优点

1. HTTPS传输数据过程中使用密钥进行加密，所以安全性更高；

2. HTTPS协议可以认证用户和服务器，确保数据发送到正确的用户和服务器。

- 缺点

1. HTTPS握手阶段延时较高：由于在进行HTTP会话之前还需要进行SSL握手，因此HTTPS协议握手阶段延时增加；

2. HTTPS部署成本高：一方面HTTPS协议需要使用证书来验证自身的安全性，所以需要购买CA证书；另一方面由于采用HTTPS协议需要进行加解密的计算，占用CPU资源较多，需要的服务器配置或数目高。

### HTTPS连接建立过程及SSL工作流程

SSL/TLS 协议基本流程（rsa原理）：

- 客户端向服务器索要并验证服务器的公钥。
- 双方协商生产「会话秘钥」。
- 双方采用「会话秘钥」进行加密通信。

前两步也就是 SSL/TLS 的建立过程，也就是 TLS 握手阶段，SSL/TLS 的「握手阶段」涉及**四次**通信。SSL/TLS 协议建立的详细流程：

1. 客户端给出协议版本号、一个客户端生成的随机数（Client random），以及客户端支持的加密方法。
2. 服务器确认双方使用的加密方法，并给出数字证书、以及一个服务器生成的随机数（Server random）。
3. 客户端确认数字证书有效，然后生成一个新的随机数（Premaster secret），并使用数字证书中的公钥，加密这个随机数，发给服务器。
4. 服务器使用自己的私钥，获取客户端发来的随机数（Premaster secret）。
5. 客户端和服务器根据约定的加密方法，使用前面的三个随机数，生成”对话密钥”（session key），用来加密接下来的整个对话过程。

### Cookie和Session的区别？

- **作用范围不同**，Cookie 保存在客户端，Session 保存在服务器端。
- **有效期不同**，Cookie 可设置为长时间保持，比如我们经常使用的默认登录功能，Session 一般失效时间较短，客户端关闭或者 Session 超时都会失效。
- **隐私策略不同**，Cookie 存储在客户端，容易被窃取；Session 存储在服务端，安全性相对 Cookie 要好一些。
- **存储大小不同**， 单个 Cookie 保存的数据不能超过 4K；对于 Session 来说存储没有上限，但出于对服务器的性能考虑，Session 内不要存放过多的数据，并且需要设置 Session 删除机制。

## HTTP/1.1、HTTP/2、HTTP/3的演变

### HTTP/1.1 相比 HTTP/1.0 提高了什么性能？

- 使用 TCP 长连接的方式改善了 HTTP/1.0 短连接造成的性能开销。
- 支持管道（pipeline）网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。

### HTTP/2 做了什么优化？

HTTP/2 协议是基于 HTTPS 的，所以 HTTP/2 的安全性也是有保障的。

那 HTTP/2 相比 HTTP/1.1 性能上的改进：

1. **头部压缩**

HTTP/2 会**压缩头**，如果同时发出多个请求，如果请求头是一样的或是相似的，那么会消除重复的部分。

这就是所谓的 `HPACK` 算法：在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就提高速度了。

2. **二进制格式**

HTTP/2 不再像 HTTP/1.1 里的纯文本形式的报文，而是采用了**二进制格式**，头信息和数据体都是二进制（统称为**帧**：头信息帧和数据帧）。收到报文后，无需再将明文的报文转成二进制，而是直接解析二进制报文，增加了数据传输的效率。

3. **数据流**

HTTP/2 的数据包不是按顺序发送的，同一个连接里面连续的数据包，可能属于不同的回应。因此，必须要对数据包做标记，指出它属于哪个回应。

在 HTTP/2 中每个请求或相应的所有数据包，称为一个数据流（`Stream`）。每个数据流都标记着一个独一无二的编号（Stream ID），**不同 Stream 的帧是可以乱序发送的（因此可以并发不同的 Stream ）**，因为每个帧的头部会携带 Stream ID 信息，所以接收端可以通过 Stream ID 有序组装成 HTTP 消息。

4. **多路复用**

HTTP/2 可以在一个连接中并发多个请求或回应，而不用按照顺序一一对应。移除了 HTTP/1.1 中的串行请求，不需要排队等待，也就不会再出现「**队头阻塞**」问题，降低了延迟，大幅度提高了连接的利用率。

5. **服务器推送**

HTTP/2 还在一定程度上改善了传统的「请求 - 应答」工作模式，服务不再是被动地响应，也可以**主动**向客户端发送消息。

### HTTP/2的缺陷

HTTP/2 还是存在**队头阻塞**的问题，只不过问题不是在 HTTP 这一层面，而是在 **TCP**这一层。

HTTP/2 是基于 TCP 协议来传输数据的，TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且连续的，这样内核才会将缓冲区里的数据返回给 HTTP 应用。当前一个字节数据没有到达时，后收到的字节数据只能存放在内核缓冲区里，只有等到这一个字节数据到达时，HTTP/2 应用层才能从内核中拿到数据，这就是 **HTTP/2 队头阻塞**问题。

所以，一旦发生了丢包现象，就会触发 TCP 的**重传机制**，这样在一个 TCP 连接中的所有的 HTTP 请求都必须等待这个丢了的包被重传回来。

### HTTP/3 做了哪些优化？

 HTTP/1.1 和 HTTP/2 都有队头阻塞的问题：

- HTTP/1.1 中的管道虽然解决了请求的队头阻塞，但是**没有解决响应的队头阻塞**，因为服务端需要按顺序响应收到的请求，如果服务端处理某个请求消耗的时间比较长，那么只能等相应完这个请求后， 才能处理下一个请求，这属于 HTTP 层队头阻塞。
- HTTP/2 虽然通过多个请求复用一个 TCP 连接解决了 HTTP 的队头阻塞 ，但是**一旦发生丢包，就会阻塞住所有的 HTTP 请求**，这属于 TCP 层队头阻塞。

HTTP/2 队头阻塞的问题是因为 TCP，所以 **HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP**。

UDP的发生是不管顺序，也不管丢包的，所以不会出现像 HTTP/2 队头阻塞的问题。虽然 UDP 是不可靠传输的，但基于 UDP 的 **QUIC 协议** 可以实现类似 TCP 的可靠性传输。QUIC 有以下 3 个特点：

1. **无队头阻塞**

QUIC 连接上**当某个数据流发生丢包时，只会阻塞这个数据流，其他数据流不会受到影响，因此不存在队头阻塞问题**。这与 HTTP/2 不同，HTTP/2 只要某个数据流中的数据包丢失了，其他数据流也会因此受影响。

2. **更快的连接建立**

但是 HTTP/3 的 QUIC 协议并不是与 TLS 分层，而是QUIC 内部包含了 TLS，它在自己的帧会携带 TLS 里的“记录”，再加上 QUIC 使用的是 TLS/1.3，因此仅需 1 个 RTT 就可以「同时」完成建立连接与密钥协商。

3. **连接迁移**

基于 TCP 传输协议的 HTTP 协议，由于是通过四元组（源 IP、源端口、目的 IP、目的端口）确定一条 TCP 连接，那么**当移动设备的网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立连接**。而建立连接的过程包含 TCP 三次握手和 TLS 四次握手的时延，以及 TCP 慢启动的减速过程，给用户的感觉就是网络突然卡顿了一下，因此连接的迁移成本是很高的。

而 QUIC 协议没有用四元组的方式来“绑定”连接，而是通过**连接 ID**来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了**连接迁移**的功能。

所以， QUIC 是一个在 UDP 之上的**伪** TCP + TLS + HTTP/2 的多路复用的协议。

QUIC 是新协议，对于很多网络设备，根本不知道什么是 QUIC，只会当做 UDP，这样会出现新的问题，因为有的网络设备是会丢掉 UDP 包的，而 QUIC 是基于UDP 实现的，那么如果网络设备无法识别这个是 QUIC 包，那么就会当作 UDP包，然后被丢弃。

所以，HTTP/3 现在普及的进度非常的缓慢，不知道未来 UDP 是否能够逆袭 TCP。

## UDP 和 TCP 有什么区别呢？分别的应用场景是？

**TCP 和 UDP 区别：**

1. **连接**

- TCP 是面向连接的传输层协议，传输数据前先要建立连接。
- UDP 是不需要连接，即刻传输数据。

2. **服务对象**

- TCP 是一对一的两点服务，即一条连接只有两个端点。
- UDP 支持一对一、一对多、多对多的交互通信

3. **可靠性**

- TCP 是可靠交付数据的，数据可以无差错、不丢失、不重复、按需到达。
- UDP 是尽最大努力交付，不保证可靠交付数据。

4. **拥塞控制、流量控制**

- TCP 有拥塞控制和流量控制机制，保证数据传输的安全性。
- UDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率。

5. **首部开销**

- TCP 首部长度较长，会有一定的开销，首部在没有使用「选项」字段时是 `20` 个字节，如果使用了「选项」字段则会变长的。
- UDP 首部只有 8 个字节，并且是固定不变的，开销较小。

6. **传输方式**

- TCP 是流式传输，没有边界，但保证顺序和可靠。
- UDP 是一个包一个包的发送，是有边界的，但可能会丢包和乱序。

7. **分片不同**

- TCP 的数据大小如果大于 MSS 大小，则会在传输层进行分片，目标主机收到后，也同样在传输层组装 TCP 数据包，如果中途丢失了一个分片，只需要传输丢失的这个分片。
- UDP 的数据大小如果大于 MTU 大小，则会在 IP 层进行分片，目标主机收到后，在 IP 层组装完数据，接着再传给传输层。

**TCP 和 UDP 应用场景：**

由于 TCP 是面向连接，能保证数据的可靠性交付，因此经常用于：

- `FTP` 文件传输；
- HTTP / HTTPS；

由于 UDP 面向无连接，它可以随时发送数据，再加上UDP本身的处理既简单又高效，因此经常用于：

- 包总量较少的通信，如 `DNS` 、`SNMP` 等；
- 视频、音频等多媒体通信；
- 广播通信；

## TCP三次握手

### TCP三次握手过程

- 一开始，客户端和服务端都处于 `CLOSED` 状态。先是服务端主动监听某个端口，处于 `LISTEN` 状态；
- 客户端会随机初始化序号为`x`，将此序号置于 TCP 首部的「序号」字段中，同时把 `SYN` 标志位置为 `1` ，表示 `SYN` 报文。接着把第一个 SYN 报文发送给服务端，表示向服务端发起连接，该报文不包含应用层数据，之后客户端处于 `SYN-SENT` 状态；
- 服务端收到客户端的 `SYN` 报文后，首先服务端也随机初始化自己的序号为`y`，将此序号填入 TCP 首部的「序号」字段中，其次把 TCP 首部的「确认应答号」字段填入 `x + 1`, 接着把 `SYN` 和 `ACK` 标志位置为 `1`。最后把该报文发给客户端，该报文也不包含应用层数据，之后服务端处于 `SYN-RCVD` 状态；
- 客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先将应答报文 TCP 首部 `ACK` 标志位置为 `1` ，其次「确认应答号」字段填入 `y + 1` ，最后把报文发送给服务端，这次报文可以携带客户到服务器的数据，之后客户端处于 `ESTABLISHED` 状态；
- 服务器收到客户端的应答报文后，也进入 `ESTABLISHED` 状态。

从上面的过程可以发现**第三次握手是可以携带数据的，前两次握手是不可以携带数据的**，这也是面试常问的题。

一旦完成三次握手，双方都处于 `ESTABLISHED` 状态，此时连接就已建立完成，客户端和服务端就可以相互发送数据了。

### 为什么是三次握手？不是两次、四次？

- **防止历史连接的建立**（主要原因）

客户端连续发送多次 SYN 建立连接的报文，在**网络拥堵**情况下：一个「旧 SYN 报文」比「最新的 SYN 」 报文早到达了服务端，那么此时服务端就会回一个 `SYN + ACK` 报文给客户端。客户端收到后可以根据自身的上下文，判断这是一个历史连接（序列号过期或超时），那么客户端就会发送 `RST` 报文给服务端，表示中止这一次连接。

**如果是两次握手连接，就无法阻止历史连接**，那为什么 TCP 两次握手为什么无法阻止历史连接呢？

主要是因为**在两次握手的情况下，服务端没有中间状态给客户端来阻止历史连接，导致服务端可能建立一个历史连接，造成资源浪费**。

两次握手的情况下，服务端在收到 SYN 报文后，就进入 ESTABLISHED 状态，意味着这时可以给对方发送数据，但是客户端此时还没有进入 ESTABLISHED 状态。假设这次是历史连接，客户端判断到此次连接为历史连接，那么就会回 RST 报文来断开连接，而服务端在第一次握手的时候就进入 ESTABLISHED 状态，所以它可以发送数据的，但是它并不知道这个是历史连接，它只有在收到 RST 报文后，才会断开连接。

可以看到，上面这种场景下，服务端在向客户端发送数据前，并没有阻止掉历史连接，导致服务端建立了一个历史连接，又白白发送了数据，妥妥地浪费了服务端的资源。

因此，**要解决这种现象，最好就是在服务端发送数据前，也就是建立连接之前，要阻止掉历史连接，这样就不会造成资源浪费，而要实现这个功能，就需要三次握手**。

- **同步双方的初始序列号**

TCP 协议的通信双方， 都必须维护一个「序列号」， 序列号是可靠传输的一个关键因素，它的作用：

1. 接收方可以去除重复的数据；

2. 接收方可以根据数据包的序列号按序接收；

3. 可以标识发送出去的数据包中， 哪些是已经被对方收到的（通过 ACK 报文中的序列号知道）；

可见，序列号在 TCP 连接中占据着非常重要的作用，所以当客户端发送携带「初始序列号」的 `SYN` 报文的时候，需要服务端回一个 `ACK` 应答报文，表示客户端的 SYN 报文已被服务端成功接收，那当服务端发送「初始序列号」给客户端的时候，依然也要得到客户端的应答回应，**这样一来一回，才能确保双方的初始序列号能被可靠的同步。**

四次握手其实也能够可靠的同步双方的初始化序号，但由于**第二步和第三步可以优化成一步**，所以就成了「三次握手」。

而两次握手只保证了一方的初始序列号能被对方成功接收，没办法保证双方的初始序列号都能被确认接收。

- **避免资源浪费**

如果只有「两次握手」，当客户端的 `SYN` 请求连接在网络中阻塞，客户端没有接收到 `ACK` 报文，就会重新发送 `SYN` ，由于没有第三次握手，服务器不清楚客户端是否收到了自己发送的建立连接的 `ACK` 确认信号，所以每收到一个 `SYN` 就只能先主动建立一个连接，这会造成什么情况呢？

如果客户端的 `SYN` 阻塞了，重复发送多次 `SYN` 报文，那么服务器在收到请求后就会**建立多个冗余的无效链接，造成不必要的资源浪费。**

即两次握手会造成消息滞留情况下，服务器重复接受无用的连接请求 `SYN` 报文，而造成重复分配资源。

**总结**：不使用「两次握手」和「四次握手」的原因：

- 「两次握手」：无法防止历史连接的建立，会造成双方资源的浪费，也无法可靠的同步双方序列号；
- 「四次握手」：三次握手就已经理论上最少可靠连接建立，所以不需要使用更多的通信次数。

### 第三次握手丢失会发生什么？

客户端收到服务端的 SYN-ACK 报文后，就会给服务端回一个 ACK 报文，也就是第三次握手，此时客户端状态进入到 `ESTABLISH` 状态。

因为这个第三次握手的 ACK 是对第二次握手的 SYN 的确认报文，所以当第三次握手丢失了，如果服务端那一方迟迟收不到这个确认报文，就会触发超时重传机制，重传 SYN-ACK 报文，直到收到第三次握手，或者达到最大重传次数。

注意，**ACK 报文是不会有重传的，当 ACK 丢失了，就由对方重传对应的报文**。

## TCP四次挥手

### TCP四次挥手过程

- 客户端打算关闭连接，此时会发送一个 TCP 首部 `FIN` 标志位被置为 `1` 的报文，也即 `FIN` 报文，之后客户端进入 `FIN_WAIT_1` 状态。
- 服务端收到该报文后，就向客户端发送 `ACK` 应答报文，接着服务端进入 `CLOSED_WAIT` 状态。
- 客户端收到服务端的 `ACK` 应答报文后，之后进入 `FIN_WAIT_2` 状态。
- 等待服务端处理完数据后，也向客户端发送 `FIN` 报文，之后服务端进入 `LAST_ACK` 状态。
- 客户端收到服务端的 `FIN` 报文后，回一个 `ACK` 应答报文，之后进入 `TIME_WAIT` 状态
- 服务器收到了 `ACK` 应答报文后，就进入了 `CLOSED` 状态，至此服务端已经完成连接的关闭。
- 客户端在经过 `2MSL` 一段时间后，自动进入 `CLOSED` 状态，至此客户端也完成连接的关闭。

每个方向都需要**一个 FIN 和一个 ACK**，因此通常被称为**四次挥手**。这里一点需要注意是：**主动关闭连接的，才有 TIME_WAIT 状态。**

### 为什么挥手需要四次？

再来回顾下四次挥手双方发 `FIN` 包的过程，就能理解为什么需要四次了。

- 关闭连接时，客户端向服务端发送 `FIN` 时，仅仅表示客户端不再发送数据了但是还能接收数据。
- 服务器收到客户端的 `FIN` 报文时，先回一个 `ACK` 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 `FIN` 报文给客户端来表示同意现在关闭连接。

从上面过程可知，服务端通常需要等待完成数据的发送和处理，所以服务端的 `ACK` 和 `FIN` 一般都会分开发送，从而比三次握手导致多了一次。

### 为什么需要 TIME_WAIT 状态？

主动发起关闭连接的一方，才会有 `TIME-WAIT` 状态。需要 TIME-WAIT 状态，主要是两个原因：

- 防止历史连接中的数据，被后面相同四元组的连接错误的接收；

为了防止历史连接中的数据，被后面相同四元组的连接错误的接收，因此 TCP 设计了 TIME_WAIT 状态，状态会持续 `2MSL` 时长，这个时间**足以让两个方向上的数据包都被丢弃，使得原来连接的数据包在网络中都自然消失，再出现的数据包一定都是新建立连接所产生的。**

- 保证「被动关闭连接」的一方，能被正确的关闭；

TIME-WAIT 作用是**等待足够的时间以确保最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭。**

### close_wait大量出现？

close_wait状态是在TCP四次挥手的时候收到FIN，但是没有发送自己的FIN时出现的，服务器出现大量close_wait状态的原因：

服务器内部业务处理占用了过多时间，都没能处理完业务，或者还有数据需要发送，或者服务器的业务逻辑有问题，没有执行close()方法，服务端socket忙于读写；

处理方法：

1. 代码层面做到

  第一：使用完socket就调用close方法；

  第二：socket读控制，当读取的长度为0时（读到结尾），立即close；

  第三：如果read返回-1，出现错误，检查error返回码，有三种情况：INTR（被中断，可以继续读取），WOULDBLOCK（表示当前socket_fd文件描述符是非阻塞的，但是现在被阻塞了），AGAIN（表示现在没有数据稍后重新读取）。如果不是AGAIN，立即close

2. 可以设置TCP的连接时长 keep_alive_time，还有TCP监控连接的频率以及连接没有活动多长时间被迫断开连接。

## TCP如何保证可靠性

### 重传机制

TCP 实现可靠传输的方式之一，是通过序列号与确认应答。在 TCP 中，当发送端的数据到达接收主机时，接收端主机会返回一个确认应答消息，表示已收到消息。 TCP 针对数据包丢失的情况，会用**重传机制**解决，常见的有超时重传、快速重传、SACK方法、 Duplicate SACK。

- **超时重传**

超时重传就是在发送数据时，设定一个定时器，当超过指定的时间后，没有收到对方的 `ACK` 确认应答报文，就会重发该数据，超时重传时间 RTO 的值应该略大于报文往返 RTT 的值。

如果超时重发的数据，再次超时的时候，又需要重传的时候，TCP 的策略是**超时间隔加倍**，也就是每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍。两次超时，就说明网络环境差，不宜频繁反复发送。

超时触发重传存在的问题是，超时周期可能相对较长。那是不是可以有更快的方式呢？——快速重传

- **快速重传**

快速重传**不以时间为驱动，而是以数据驱动重传**。快速重传的工作方式是当收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段。

快速重传机制解决了超时时间的问题，但是它依然面临着另外一个问题：就是**重传的时候，是重传之前的一个，还是重传所有的问题。**为了解决不知道该重传哪些 TCP 报文的问题，于是就有 `SACK` 方法。

- **SACK方法**

`SACK`（ Selective Acknowledgment 选择性确认），这种方式需要在 TCP 头部「选项」字段里加一个 `SACK` 的东西，它**可以将缓存的地图发送给发送方**，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以**只重传丢失的数据**。

- **Duplicate SACK**

Duplicate SACK 又称 `D-SACK`，其主要**使用了 SACK 来告诉「发送方」有哪些数据被重复接收了。**

### 滑动窗口

TCP 会利用窗口控制来提高传输速度，在一个窗口大小内，不用等到应答返回就能发送下一段数据，窗口大小就是无需等待确认而可以继续发送数据的最大值。如果不使用窗口控制，每一个没收到确认应答的数据都要重发。

### 流量控制

流量控制就是让发送方的发送速率不要太快，防止接收方接受窗口溢出产生丢包，既要让接收方来得及接收，也不要使网络发生拥塞。利用滑动窗口机制可以很方便地在 TCP 连接上实现流量控制。

发送方维护一个发送窗口，发送窗口的大小表示在未收到接收方发来确认的情况下，最多还可以发送多少个帧。只有接收窗口向前滑动时（并且接收方发送了确认），发送窗口才有可能（只有发送方收到确认才是一定）向前滑动。

接收方维护一个接收窗口，只有当接收到的帧的序号落入接收窗口内才收下该帧，将接收窗口向前滑动一个位置，并给发送方发回确认。若接收到的顿的序号落在接收窗口之外，则一律将其丢弃。

### 拥塞控制

在网络出现拥堵时，如果继续发送大量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是一重传就会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，这个情况就会进入恶性循环被不断地放大。于是，就有了**拥塞控制**，控制的目的就是**避免「发送方」的数据填满整个网络。**

发送方维护一个拥塞窗口，它的大小会随着网络的拥塞程度动态变化的。只要网络中没有出现拥塞，窗口大小就会增大；但网络中出现了拥塞，窗口大小就会减少。

拥塞控制主要是四个算法：**慢启动、拥塞避免、拥塞发生、快速恢复**。

**慢启动**算法的规则：当发送方每收到一个 ACK，拥塞窗口大小就会加 1，会导致发包个数呈**指数性**的增长。

拥塞窗口大小低于慢启动门限时采用慢启动算法，超过慢启动门限时采用拥塞避免算法。

**拥塞避免**算法的规则是：**每当收到一个 ACK 时，cwnd 增加 1/cwnd。**拥塞避免算法就是将原本慢启动算法的指数增长变成了**线性增长**，还是增长阶段，但是增长速度缓慢了一些。就这么一直增长着后，网络就会慢慢进入了拥塞的状况了，于是就会出现丢包现象，这时就需要对丢失的数据包进行重传。当触发了重传机制，也就进入了「拥塞发生算法」。

当网络出现拥塞，也就是会发生数据包重传，重传机制主要有两种：超时重传、快速重传。

这两种使用的拥塞发送算法是不同的，接下来分别来说说。

> 发生**超时重传**的拥塞发生算法

当发生了「超时重传」，则就会使用拥塞发生算法。这个时候，`ssthresh`和 `cwnd `的值会发生变化：

- `ssthresh` 设为 `cwnd/2`，
- `cwnd` 重置为 `1`

接着，就重新开始慢启动，慢启动是会突然减少数据流的。这真是一旦「超时重传」，马上回到解放前。但是这种方式太激进了，反应也很强烈，会造成网络卡顿。

> 发生**快速重传**的拥塞发生算法

还有更好的方式，前面我们讲过「快速重传算法」。当接收方发现丢了一个中间包的时候，发送三次前一个包的 ACK，于是发送端就会快速地重传，不必等待超时再重传。

TCP 认为这种情况不严重，因为大部分没丢，只丢了一小部分，则 `ssthresh` 和 `cwnd` 变化如下：

- `cwnd = cwnd/2` ，也就是设置为原来的一半;
- `ssthresh = cwnd`;
- 进入快速恢复算法，重新进入拥塞避免状态

## IP层相关技术

### DNS 的解析过程？

1. 浏览器搜索**自己的DNS缓存**
2. 若没有，则搜索**操作系统中的DNS缓存和hosts文件**
3. 若没有，则操作系统将域名发送至**本地域名服务器**，本地域名服务器查询自己的DNS缓存，查找成功则返回结果，否则依次向**根域名服务器、顶级域名服务器、权限域名服务器**发起查询请求，最终返回IP地址给本地域名服务器
4. 本地域名服务器将得到的IP地址返回给**操作系统**，同时自己也**将IP地址缓存起来**
5. 操作系统将 IP 地址返回给浏览器，同时自己也将IP地址缓存起来
6. 浏览器得到域名对应的IP地址

### ARP和RARP

MAC 的作用则是实现「直连」的两个设备之间通信，而 IP 则负责在「没有直连」的两个网络之间进行通信传输。源IP地址和目标IP地址在传输过程中是不会变化的，只有源 MAC 地址和目标 MAC 一直在变化。

在传输一个 IP 数据报的时候，确定了源 IP 地址和目标 IP 地址后，就会通过主机「路由表」确定 IP 数据包下一跳。然而，网络层的下一层是数据链路层，所以我们还要知道「下一跳」的 MAC 地址。由于主机的路由表中可以找到下一跳的 IP 地址，所以可以通过 **ARP 协议**，求得下一跳的 MAC 地址。

ARP 是借助 **ARP 请求与 ARP 响应**两种类型的包确定 MAC 地址的。

主机会通过**广播发送 ARP 请求**，这个包中包含了想要知道的 MAC 地址的主机 IP 地址。当同个链路中的所有设备收到 ARP 请求时，会去拆开 ARP 请求包里的内容，如果 ARP 请求包中的目标 IP 地址与自己的 IP 地址一致，那么这个设备就将自己的 MAC 地址塞入 **ARP 响应包**返回给主机。

操作系统通常会把第一次通过 ARP 获取的 MAC 地址缓存起来，以便下次直接从缓存中找到对应 IP 地址的 MAC 地址。不过，MAC 地址的缓存是有一定期限的，超过这个期限，缓存的内容将被清除。

ARP 协议是已知 IP 地址求 MAC 地址，那 **RARP **协议正好相反，它是**已知 MAC 地址求 IP 地址**。例如将打印机服务器等小型嵌入式设备接入到网络时就经常会用得到。

通常这需要架设一台 `RARP` 服务器，在这个服务器上注册设备的 MAC 地址及其 IP 地址。然后再将这个设备接入到网络，接着：

- 该设备会发送一条「我的 MAC 地址是XXXX，请告诉我，我的IP地址应该是什么」的请求信息。
- RARP 服务器接到这个消息后返回「MAC地址为 XXXX 的设备，IP地址为 XXXX」的信息给这个设备。

最后，设备就根据从 RARP 服务器所收到的应答信息设置自己的 IP 地址。

### NAT

## TCP粘包和拆包

**解释**

TCP是⾯向流，没有界限的⼀串数据。TCP底层并不了解上层业务数据的具体含义，它会根据TCP缓冲区的实际情况进⾏包的划分，所以在业务上认为，⼀个完整的包可能会被TCP拆分成多个包进⾏发送，也有可能把多个⼩的包封装成⼀个⼤的数据包发送。

由于UDP不是面向‘流’的，而且UDP是具有消息边界的。也就是说UDP的发送的每一个数据包都是独立的。所以UDP并不存在粘包的问题。

**为什么会产⽣粘包和拆包呢?**

要发送的数据⼩于TCP发送缓冲区的⼤⼩，TCP将多次写⼊缓冲区的数据⼀次发送出去，将会发⽣粘包；

接收数据端的应⽤层没有及时读取接收缓冲区中的数据，将发⽣粘包；

要发送的数据⼤于TCP发送缓冲区剩余空间⼤⼩，将会发⽣拆包；

待发送数据⼤于MSS（最⼤报⽂⻓度），TCP在传输前将进⾏拆包。即TCP报⽂⻓度-TCP头部⻓度>MSS。

**解决⽅法**

发送端将每个数据包封装为固定⻓度；

在数据尾部增加特殊字符进⾏分割；

将数据分为两部分，⼀部分是头部，⼀部分是内容体；其中头部结构⼤⼩固定，且有⼀个字段声明内容体的⼤⼩。

详细解释：

发送端给每个数据包添加包首部，首部中应该至少包含数据包的长度，这样接收端在接收到数据后，通过读取包首部的长度字段，便知道每一个数据包的实际长度了。

发送端将每个数据包封装为固定长度（不够的可以通过补0填充），这样接收端每次从接收缓冲区中读取固定长度的数据就自然而然的把每个数据包拆分开来。

可以在数据包之间设置边界，如添加特殊符号，这样，接收端通过这个边界就可以将不同的数据包拆分开。

# 操作系统













